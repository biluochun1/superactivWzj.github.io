[{"title":"我单方面有老婆了","url":"/2019/07/23/20190723/","content":"** {{ title }}：** <Excerpt in index | 首页摘要>\n<!-- more -->\n<The rest of contents | 余下全文>\n\n年初搭的这个博客，当初是为了记录一下平时学习的内容，做个复习。现在发现，平时也没有什么技术写出来和分享的。不如写点平时生活想的东西，做个人。\n其实前几天一直在备忘录写，昨天晚上想写进博客里。\n\n20190720 3.00\n我喜欢她。\n\n太羞耻了，后面写的我不想放出来了。\n\n![](IMG_0684.jpg)\n![](IMG_0685.jpg)\n\n赵祎静，我喜欢你。","tags":["杂"]},{"title":"java-stream","url":"/2019/06/11/java-stream/","content":"** {{ title }}：** <Excerpt in index | 首页摘要>\njava8新特性，对集合（Collection）对象功能的增强，它专注于对集合对象进行各种非常便利、高效的聚合操作（aggregate operation），或者大批量数据操作 (bulk data operation)。\n<!-- more -->\n<The rest of contents | 余下全文>\n\n## 流的构造与转换\n\n```java\n// make stream\n// 1. Individual values\nStream stream = Stream.of(\"a\", \"b\", \"c\");\n// 2. Arrays\nString [] strArray = new String[] {\"a\", \"b\", \"c\"};\nstream = Stream.of(strArray);\nstream = Arrays.stream(strArray);\n// 3. Collections\nList<String> list = Arrays.asList(strArray);\nstream = list.stream();\n// 4 数值流的构造\nIntStream.of(new int[{1,2,3}).forEach(System.out::println);\nIntStream.range(1,3).forEach(System.out::println;\nIntStream.rangeClosed(1,3).forEach(System.out::println);                         \n                          \n```\n\n> IntStream、LongStream、DoubleStream。当然我们也可以用 Stream<Integer>、Stream<Long> >、Stream<Double>，但是 boxing 和 unboxing 会很耗时，所以特别为这三种基本数值型提供了对应的 Stream。\n\n```java\n// 流转换为其它数据结构\n// 1. Array\nString[] strArray1 = stream.toArray(String[]::new);\n// 2. Collection\nList<String> list1 = stream.collect(Collectors.toList());\nList<String> list2 = stream.collect(Collectors.toCollection(ArrayList::new));\nSet set1 = stream.collect(Collectors.toSet());\nStack stack1 = stream.collect(Collectors.toCollection(Stack::new));\n// 3. String\nString str = stream.collect(Collectors.joining()).toString();\n```\n\n## map\n\n一种映射关系，将一个集合映射到另一个集合，一一映射\n\n```java\n// 转换大写\nList<String> output = wordList.stream().\nmap(String::toUpperCase).\ncollect(Collectors.toList());\n// 求平方数\nList<Integer> nums = Arrays.asList(1, 2, 3, 4);\nList<Integer> squareNums = nums.stream().\nmap(n -> n * n).\ncollect(Collectors.toList());\n```\n\n一对多映射关系的，这时需要 flatMap，（多用于多个流转一个流）\n\n```java\nStream<List<Integer>> inputStream = Stream.of(\n Arrays.asList(1),\n Arrays.asList(2, 3),\n Arrays.asList(4, 5, 6)\n );\nStream<Integer> outputStream = inputStream.\nflatMap((childList) -> childList.stream());\n// flatMap 把 input Stream 中的层级结构扁平化，就是将最底层元素抽出来放到一起，最终 output 的新 Stream 里面已经没有 List 了，都是直接的数字\n```\n\n## filter\n\n集合过滤器\n\n```java\n// 过滤奇数\nInteger[] sixNums = {1, 2, 3, 4, 5, 6};\nInteger[] evens =\nStream.of(sixNums).filter(n -> n%2 == 0).toArray(Integer[]::new);\n```\n\n## forEach\n\n对集合每个元素执行操作\n\n```java\n// 打印男性姓名\n// Java 8\nroster.stream()\n .filter(p -> p.getGender() == Person.Sex.MALE)\n .forEach(p -> System.out.println(p.getName()));\n// Pre-Java 8\nfor (Person p : roster) {\n if (p.getGender() == Person.Sex.MALE) {\n System.out.println(p.getName());\n }\n}\n```\n\n## optional\n\n一种返回值类型\t\n\n```java\nString strA = \" abcd \", strB = null;\nprint(strA);\nprint(\"\");\nprint(strB);\ngetLength(strA);\ngetLength(\"\");\ngetLength(strB);\npublic static void print(String text) {\n // Java 8\n Optional.ofNullable(text).ifPresent(System.out::println);\n // Pre-Java 8\n // if (text != null) {\n // System.out.println(text);\n // }\n }\npublic static int getLength(String text) {\n // Java 8\nreturn Optional.ofNullable(text).map(String::length).orElse(-1);\n // Pre-Java 8\n // return if (text != null) ? text.length() : -1;\n };\n```\n\n\n\n```java\nInteger i = new Integer(2);\nOptional.ofNullable(i).ifPresent(t -> t = 3);\n\nint j = 4;\nOptional.ofNullable(i).ifPresent(t -> t = 5);\n\nUser user = new User(1);\nOptional.ofNullable(i).ifPresent(t -> t = new User(2));\n//i j user 的值不会变 i user 因为方法内部引用了其他对象 j 因为值传递\n//1.如果是基本类型，java的传递是值传递,即一个方法不能改变一个基本数据类型的参数（数值型和布尔型）\n//2.如果是对象类型，java的传递是引用传递，即一个方法可以改变一个对象参数的状态，如 user.setage()\n//3.如果是对象类型，java的传递是引用传递，但方法内部改变了对象的引用，那该对象本身不变，即一个方法不能让对象参数引用一个新的对象\n```\n\n## reduce\n\n```java\n// 字符串连接，concat = \"ABCD\"\nString concat = Stream.of(\"A\", \"B\", \"C\", \"D\").reduce(\"\", String::concat); \n// 求最小值，minValue = -3.0\ndouble minValue = Stream.of(-1.5, 1.0, -3.0, -2.0).reduce(Double.MAX_VALUE, Double::min); \n// 求和，sumValue = 10, 有起始值\nint sumValue = Stream.of(1, 2, 3, 4).reduce(0, Integer::sum);\n// 求和，sumValue = 10, 无起始值\nsumValue = Stream.of(1, 2, 3, 4).reduce(Integer::sum).get();\n// 过滤，字符串连接，concat = \"ace\"\nconcat = Stream.of(\"a\", \"B\", \"c\", \"D\", \"e\", \"F\").\n filter(x -> x.compareTo(\"Z\") > 0).\n reduce(\"\", String::concat);\n```\n\n## sorted\n\n```java\nList<Person> personList2 = persons.stream().limit(2).sorted((p1, p2) -> p1.getName().compareTo(p2.getName())).collect(Collectors.toList());\n```\n\n\n"},{"title":"libc++abi.dylib:问题","url":"/2019/06/10/libc++abi.dylib/","content":"** {{ title }}：** <Excerpt in index | 首页摘要>\nMacBook环境使用Matplotlib报错 libc++abi.dylib: terminating with uncaught exception of type NSException 解决办法\n<!-- more -->\n<The rest of contents | 余下全文>\n\n```shell\n$ python main.py\n2019-06-10 16:13:58.210 python[19072:245965] -[NSApplication _setup:]: unrecognized selector sent to instance 0x7f9e10e1d340\n2019-06-10 16:13:58.212 python[19072:245965] *** Terminating app due to uncaught exception 'NSInvalidArgumentException', reason: '-[NSApplication _setup:]: unrecognized selector sent to instance 0x7f9e10e1d340'\n*** First throw call stack:\n(\n\t0   CoreFoundation                      0x00007fff3d16aded __exceptionPreprocess + 256\n\t1   libobjc.A.dylib                     0x00007fff69237720 objc_exception_throw + 48\n\t2   CoreFoundation                      0x00007fff3d1e8195 -[NSObject(NSObject) __retain_OA] + 0\n\t3   CoreFoundation                      0x00007fff3d10ca60 ___forwarding___ + 1486\n\t4   CoreFoundation                      0x00007fff3d10c408 _CF_forwarding_prep_0 + 120\n\t5   libtk8.6.dylib                      0x000000010e47c31d TkpInit + 413\n\t6   libtk8.6.dylib                      0x000000010e3d417e Initialize + 2622\n\t7   _tkinter.cpython-36m-darwin.so      0x000000010e1fca16 _tkinter_create + 1174\n\t8   python                              0x000000010d78f068 _PyCFunction_FastCallDict + 200\n\t9   python                              0x000000010d86461f call_function + 143\n\t10  python                              0x000000010d862175 _PyEval_EvalFrameDefault + 46837\n\t11  python                              0x000000010d8558c9 _PyEval_EvalCodeWithName + 425\n\t12  python                              0x000000010d8652cc _PyFunction_FastCallDict + 364\n\t13  python                              0x000000010d70df80 _PyObject_FastCallDict + 320\n\t14  python                              0x000000010d7355f8 method_call + 136\n\t15  python                              0x000000010d7155ce PyObject_Call + 62\n\t16  python                              0x000000010d7b65b5 slot_tp_init + 117\n\t17  python                              0x000000010d7baaf1 type_call + 241\n\t18  python                              0x000000010d70def1 _PyObject_FastCallDict + 177\n\t19  python                              0x000000010d864718 call_function + 392\n\t20  python                              0x000000010d862175 _PyEval_EvalFrameDefault + 46837\n\t21  python                              0x000000010d865212 _PyFunction_FastCallDict + 178\n\t22  python                              0x000000010d70df80 _PyObject_FastCallDict + 320\n\t23  python                              0x000000010d7355f8 method_call + 136\n\t24  python                              0x000000010d7155ce PyObject_Call + 62\n\t25  python                              0x000000010d7b65b5 slot_tp_init + 117\n\t26  python                              0x000000010d7baaf1 type_call + 241\n\t27  python                              0x000000010d70def1 _PyObject_FastCallDict + 177\n\t28  python                              0x000000010d864718 call_function + 392\n\t29  python                              0x000000010d862175 _PyEval_EvalFrameDefault + 46837\n\t30  python                              0x000000010d8558c9 _PyEval_EvalCodeWithName + 425\n\t31  python                              0x000000010d8ae55c PyRun_FileExFlags + 252\n\t32  python                              0x000000010d8ada34 PyRun_SimpleFileExFlags + 372\n\t33  python                              0x000000010d8d47c6 Py_Main + 3734\n\t34  python                              0x000000010d705f59 main + 313\n\t35  libdyld.dylib                       0x00007fff6a305ed9 start + 1\n\t36  ???                                 0x0000000000000002 0x0 + 2\n)\nlibc++abi.dylib: terminating with uncaught exception of type NSException\n[1]    19072 abort      python main.py\n(base)\n```\n\n解决：\n\n在terminal终端下输入这个指令vim ~/.matplotlib/matplotlibrc，\n\n在打开的vim编辑器中先按字母i开启编辑模式，\n\n然后输入backend: TkAgg，如下图\n\n接着按Esc键，\n\n最后 :wq 保存并退出\n\n>Problem Cause In mac os image rendering back end of matplotlib (what-is-a-backend to render using the API of Cocoa by default). There is Qt4Agg and GTKAgg and as a back-end is not the default. Set the back end of macosx that is differ compare with other windows or linux os. \n>I resolve this issue following ways:\n>I assume you have installed the pip matplotlib, there is a directory in you root called ~/.matplotlib. \n>Create a file ~/.matplotlib/matplotlibrc there and add the following code: backend: TkAgg\n>From this link you can try different diagram.\n","tags":["mac"]},{"title":"sql_daily","url":"/2019/05/29/sql-daily/","content":"** {{ title }}：** <Excerpt in index | 首页摘要>\n记录一下sql\n<!-- more -->\n<The rest of contents | 余下全文>\n\n```sql\n查询datetime类型\nSELECT * FROM tablename \nWHERE columname BETWEEN '2012-12-25 00:00:00' AND '2012-12-25 23:59:59'\n```","tags":["sql"]},{"title":"python-daily","url":"/2019/05/08/python-daily/","content":"\n** {{ title }}：** <Excerpt in index | 首页摘要>\n记录一下平时用到的python\n<!-- more -->\n<The rest of contents | 余下全文>\n\n1. 获取文件夹下文件名字（数量）\n  \n   ```python\n   [name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))]\n   ```\n\n2. multiprocessing.Pool\n\n   ```python\n    pool = multiprocessing.Pool(n)\n    for i in range(n):\n        pool.apply_async(target,args=())\n        # 这里异步执行\n    pool.close() #主线程要close，停止加入进程\n    pool.join() #阻塞当前进程，等待pool的进程执行完毕，要join，pool的进程才会执行，另外join要在close后面\n   ```\n\n3. 生成grpc源文件\n\n   ```python\n   python -m grpc_tools.protoc -I. --python_out=. --grpc_python_out=. file.proto\n   ```\n\n4. json.dumps(dict)\n\n   ```python\n   如果dict的key用 ' ,返回后会变 \"\n   不想变的话可以 str(dict)\n   ```\n\n5. json.dumps 不能序列化np.array,需要.tolist()\n\n6. 毫秒级别时间戳\n\n    ```python\n    datetime.datetime.now().strftime(\"%H:%M:%S.%f\")\n    ```\n\n7. python grpc 使用多进程\n\n   https://github.com/grpc/grpc/blob/master/doc/fork_support.md\n\n    >In Python, multithreading is ineffective at concurrency for CPU bound tasks due to the GIL (global interpreter lock). Extension modules can release the GIL in CPU bound tasks, but that isn't an option in pure Python. Users use libraries such as multiprocessing, subprocess, concurrent.futures.ProcessPoolExecutor, etc, to work around the GIL. These modules call fork() underneath the hood. Various issues have been reported when using these modules with gRPC Python. gRPC Python wraps gRPC core, which uses multithreading for performance, and hence doesn't support fork(). Historically, we didn't support forking in gRPC, but some users seemed to be doing fine until their code started to break on version 1.6. This was likely caused by the addition of background c-threads and a background Python thread.\n","tags":["python"]},{"title":"Python-concurrent.futures","url":"/2019/04/25/python-concurrent-futures/","content":"\n** {{ title }}：** <Excerpt in index | 首页摘要>\nPython-concurrent.futures ThreadPoolExecutor的使用\n<!-- more -->\n<The rest of contents | 余下全文>\n\n```python\n# coding:utf-8\nfrom concurrent.futures import ProcessPoolExecutor,ThreadPoolExecutor\nimport threading\nimport os,time\n\ndef task(n):\n    print('%s:%s is running' %(threading.currentThread().getName(),os.getpid()))\n    # 打印当前线程名和运行的id号码\n    time.sleep(2)\n    return n**2\n    # 返回传入参数的二次幂\n\nif __name__ == '__main__':\n    p=ThreadPoolExecutor()\n    #实例化线程池，设置线程池的数量，不填则默认为cpu的个数*5\n    futures=[]\n    # 用来保存返回的数据，做计算总计\n    for i in range(10):\n        obj=p.submit(task,i)\n        # 传入的参数是要执行的函数和该函数接受的参数\n        # -----------------------------------\n        # 这里执行的方式是异步执行\n        # p.submit(task,i).result()即同步执行\n        # -----------------------------------\n        # 上面的方法使用range循环有个高级的写法，即map内置函数\n        # obj=p.map(task,range(10))\n        # p.shutdown()\n        # -----------------------------------\n        futures.append(obj)\n        # 把返回的结果保存在空的列表中，做总计算\n    p.shutdown()\n    # 所有计划运行完毕，关闭结束线程池\n\n    print('='*30)\n    print([obj.result() for obj in futures])\n\n#上面方法也可写成下面的方法\n    # with ThreadPoolExecutor() as p:   #类似打开文件,可省去.shutdown()\n    #     future_tasks = [p.submit(task, i) for i in range(10)]\n    # print('=' * 30)\n    # print([obj.result() for obj in future_tasks])\n```\n\n关于 .result() 方法，[https://stackoverflow.com/questions/52082665/store-results-threadpoolexecutor]\n\n当调用future.result()，它会阻塞，直到值准备就绪。所以，你没有从并行性中获得任何好处 - 你开始一个任务，等待它完成，启动另一个，等待它完成。\n正确的是将future自己加到一个列表中\n\n```python\nfutures.append(p.submit(task,i))\n# l.append(p.submit(task,i).result)\n```\n\n然后，在开始所有工作后，可以开始等待它们。当需要更多控制时，有三个方式：\n(1) 直接循环遍历,会等待\n\n```python\nfor future in futures:\n    result = future.result()\n    pass\n```\n\n(2) 等待所有任务全部完成，使用wait\n\n```python\nfutures, _ = concurrent.futures.wait(futures)\nfor future in futures:\n    result = future.result()\n    pass\n```\n\n(3) 每个任务完成后立即处理它们\n\n```python\nfor result in concurrent.futures.as_completed(futures):\n    pass\n```\n\n(4) 拿到一些完成的任务\n\n```python\nwhile futures:\n    done, futures = concurrent.futures.wait(concurrent.futures.FIRST_COMPLETED)\n    for future in done:\n        result = future.result()\n        pass\n```","tags":["python 线程池"]},{"title":"Golang-study","url":"/2019/04/24/Golang-study/","content":"** {{ title }}：** <Excerpt in index | 首页摘要>\n学习 go 过程中的一些问题，记录\n<!-- more -->\n<The rest of contents | 余下全文>\n\n## 值接收者和引用接收者的方法\n\n1. 不管你的method的receiver是指针类型还是非指针类型，都是可以通过指针/非指针类型进行调用的，编译器会帮你做类型转换。\n2. 在声明一个method的receiver该是指针还是非指针类型时，你需要考虑两方面的因素，第一方面是这个对象本身是不是特别大，如果声明为非指针变量时，调用会产生一次拷贝；第二方面是如果你用指针类型作为receiver，那么你一定要注意，这种指针类型指向的始终是一块内存地址，就算你对其进行了拷贝。\n\n## go func()匿名函数引用外部参数\n\n闭包内取外部函数的参数的时候是取的地址,而不是调用闭包时刻的参数值。\n在使用go func的时候最好把可能改变的值通过值传递的方式传入到闭包之中,避免在协程运行的时候参数值改变导致结果不对。\n\n## 协程优雅推出\n\n1. 通过Channel传递退出信号 run传入一个channel等待读取退出信号，退出时再返回给main一个信号\n\n    ```go\n    func run(done chan int) {\n        for {\n                select {\n                case <-done:\n                        fmt.Println(\"exiting...\")\n                        done <- 1\n                        break\n                default:\n                }\n\n                time.Sleep(time.Second * 1)\n                fmt.Println(\"do something\")\n        }\n    }\n\n    func main() {\n        c := make(chan int)\n\n        go run(c)\n\n        fmt.Println(\"wait\")\n        time.Sleep(time.Second * 5)\n\n        c <- 1\n        <-c\n\n        fmt.Println(\"main exited\")\n    }\n    ```\n\n2. waitgroup\n\n## 优雅关闭channel\n\n单生产多消费者 生产者直接关闭channel\n\n```go\nfunc main() {\n    const MaxRandomNumber = 10000\n    const ConsumerNumber = 100\n\n    wgConsumer := sync.WaitGroup{}\n    wgConsumer.Add(NumConsumers)\n\n    channel := make(chan int, 100)\n\n    go func() {\n        for {\n            if value := rand.Intn(MaxRandomNumber); value == 0 {\n                close(channel)        //The only sender can close the channel safely\n                return\n            } else {\n                channel <- value\n            }\n        }\n    }()\n\n    for i := 0; i < ConsumerNumber; i++ {\n        go func() {\n            defer wgConsumer.Done()\n\n            for value := range channel {\n                fmt.Println(value)\n            }\n        }()\n    }\n\n    wgConsumer.Wait()\n}\n```\n\n多生产单消费者 消费端用一个关闭信号通知生产者停止生产\n\n```go\nfunc main() {\n    const MaxRandomNumber = 10000\n    const ProducerNumber = 100\n\n    wgConsumer := sync.WaitGroup{}\n    wgConsumer.Add(1)\n\n    channel := make(chan int, 100)\n    stopChannel := make(chan struct{})\n\n    for i := 0; i < ProducerNumber; i++ {\n        go func() {\n            for {\n                select {\n                case <- stopChannel:\n                        return\n                default:\n                }\n\n                select {\n                case <- stopChannel:\n                        return\n                case channel <- rand.Intn(MaxRandomNumber):\n                }\n            }\n        }()\n    }\n\n    go func() {\n        defer wgConsumer.Done()\n\n        for value := range channel {\n            if value == MaxRandomNumber-1 {\n                close(stopChannel)\n                return\n            }\n\n            fmt.Println(value)\n        }\n    }()\n\n    wgConsumer.Wait()\n}\n```\n\n多生产多消费者 引入一个额外的协调者来关闭附加的退出信号channel\n\n```go\nfunc main() {\n    const MaxRandomNumber = 10000\n    const ProducerNumber = 100\n    const ConsumerNumber = 10\n\n    wgConsumer := sync.WaitGroup{}\n    wgConsumer.Add(ProducerNumber)\n\n    channel := make(chan int, 100)\n    stopChannel := make(chan struct{})\n    toStop := make(chan string, 1)\n\n    var stopString string\n\n    go func() {\n        stopString = <- toStop\n        close(toStop)\n    }()\n\n    //producer\n    for i := 0; i < ProducerNumber; i++ {\n        go func(id string) {\n            for {\n                value := rand.Intn(MaxRandomNumber)\n                if value == 0 {\n                    select {\n                    case toStop <- \"producer-\" + id:\n                    default:\n                    }\n                    return\n                }\n\n                select {\n                case <- stopChannel:\n                        return\n                default:\n                }\n\n                select {\n                case <- stopChannel:\n                        return\n                case channel <- value:\n                }\n            }\n        }(strconv.Itoa(i))\n    }\n\n    //consumer\n    for i := 0; i < ConsumerNumber; i++ {\n        go func(id string) {\n            defer wgConsumer.Done()\n\n            for {\n                select {\n                case <- stopChannel:\n                        return\n                default:\n                }\n\n                select {\n                case <- stopChannel:\n                        return\n                case value := <-channel:\n                    if value == MaxRandomNumber-1 {\n                        select {\n                        case toStop <- \"consumer#\" + id:\n                        default:\n                        }\n                        return\n                    }\n\n                    fmt.Println(value)\n                }\n            }\n        }(strconv.Itoa(i))\n    }\n\n    wgConsumer.Wait()\n    fmt.Println(\"stopped info is \", stopString)\n}\n```\n\n## 基于 CSP 模型是如何组织程序\n\n计算 n！\n\n```go\nfunc FactCalc(in <-chan int, out chan<- int) {\n    var subIn, subOut chan int\n    for {\n        n := <-in\n        if n == 0 {\n            out <- 1\n        } else {\n            if subIn == nil {\n                subIn, subOut = make(chan int), make(chan int)\n                go FactCalc(subIn, subOut)\n            }\n            subIn <- n - 1\n            r := <-subOut\n            out <- n * r\n        }\n    }\n}\n\nfunc MakeFactFunc() func(int) int {\n    in, out := make(chan int), make(chan int)\n    go FactCalc(in, out)\n    return func(x int) int {\n        in <- x\n        return <-out\n    }\n}\n\nconst limit = 5\nfunc main() {\n    fact := MakeFactFunc()\n    for i := 0; i < limit; i++ {\n        fmt.Println(fact(i))\n    }\n}\n```\n\n每个FactCalc都会被作为一个独立的goroutine来执行，对于第i个goroutine而言，它先从第i-1个goroutine中读入一个数字n然后，如果n>0，这个goroutine需要做3件事：\n\n1. 向第i+1个goroutine写入一个n-1\n2. 从第i+1个goroutine处读回来一个数字r\n3. 将n * r写入第i-1个goroutine\n\n否则，则向第i-1个goroutine处写入一个1\n\n信号量实现\n\n一个信号量有两个操作，分别为V（signal()与P(wait()。其运作方式如下：\n\n1. 初始化，信号标 S 一个非负数的整数值。\n2. 执行 P 操作（wait()）时，信号标 S 的值将尝试被减少。当信号标 S 非正数时，进程会阻塞等待；当信号标 S 为正数时，S 被成功减少，进程可以继续往下执行。\n3. 执行 V 操作（signal()）时，信号标 S 的值将会被增加。\n\n```go\ntype Semaphore struct {\n    inc chan struct{}\n    dec chan struct{}\n}\n\nfunc (sem *Semaphore) Wait() {\n    sem.dec <- struct{}{}\n}\n\nfunc (sem *Semaphore) Signal() {\n    sem.inc <- struct{}{}\n}\n\nfunc MakeSemaphore(initVal int) *Semaphore {\n    sem := Semaphore{\n        inc: make(chan struct{}),\n        dec: make(chan struct{}),\n    }\n    go func(s int) {\n        for {\n            if s > 0 {\n                select {\n                case <-sem.inc:\n                    s = s + 1\n                case <-sem.dec:\n                    s = s - 1\n                }\n            } else {\n                <-sem.inc\n                s = s + 1\n            }\n        }\n    }(initVal)\n    return &sem\n}\n```\n\n## go读写文件\n\n```golang\n    f, err := os.Open(\"filename\")\n    defer f.Close()\n    if nil == err {\n        buff := bufio.NewReader(f)\n        for {\n            line, err := buff.ReadString('\\n')\n            if err != nil || io.EOF == err{\n                break\n            }\n            fmt.Println(line)\n        }\n    }\n```","tags":["golang"]},{"title":"Future Promise","url":"/2019/04/20/Future/","content":"** {{ title }}：** <Excerpt in index | 首页摘要>\n理解future\n<!-- more -->\n<The rest of contents | 余下全文>\n\n# Future\n\nFuture的意思是未来、期货。如果有一个事情需要很长时间才能获取结果，与其一直等待，不如先拿一张提货单。获取提货单通常耗时很短，这里的提货单即Future。获取Future对象的线程稍后会使用该Future对象来获取运行结果。如果运行结果已经出来，则可以直接获取，否则还要继续等待结果出来。这跟在办公室用App下单后凭借手机上的订单号下楼去拿喜茶时一样，如果喜茶已经做好了可以直接拿走，不然还要继续等待。\n![Future模式类图](1555775738_56_w774_h302.png)\n\n- Client：请求者，负责向FutureService发出请求，并会立即接收到结果凭据。\n- Future：封装异步任务处理结果的凭据对象，负责检查异步任务处理是否完毕和返回异步任务处理结果。\n- FutureTask：Future的具体实现类。\n- FutureService：负责真正执行异步任务，并将处理结果设置到相应的Future实例中。\n\n![Future模式时序图](1555786867_85_w496_h558.png)\n第1、2步：Client启动并创建任务处理对象FutureService。\n第3、4、5步：Client提交一个任务，FutureService立即创建一个Future对象并返回给Client。\n第6步：任务处理完毕后FutureService将结果设置到Future对象中。\n第7步：Client通过Future对象获取处理结果。\n\n# Netty Future\n\nNetty中Future的方法如下（未全部列出）：\n\n```java\n// 异步操作完成且正常终止\nboolean isSuccess();\n// 异步操作是否可以取消\nboolean isCancellable();\n// 异步操作失败的原因\nThrowable cause();\n// 添加一个监听者，异步操作完成时回调，类比javascript的回调函数\nFuture<V> addListener(GenericFutureListener<? extends Future<? super V>> listener);\nFuture<V> removeListener(GenericFutureListener<? extends Future<? super V>> listener);\n// 阻塞直到异步操作完成\nFuture<V> await() throws InterruptedException;\n// 同上，但异步操作失败时抛出异常\nFuture<V> sync() throws InterruptedException;\n// 非阻塞地返回异步结果，如果尚未完成返回null\nV getNow();\n```\n\n值得注意的是sync与await的区别，它们都是同步阻塞，不同之处是当异步操作失败时，sync将会抛出错误异常，而await不会；如下是sync源码注释。\n\n```java\n/**\n* Waits for this future until it is done, and rethrows the cause of the failure if this future\n* failed.\n*/\n```\n\nFuture的状态转换图\n\n```java\n*                                      +---------------------------+\n*                                      | Completed successfully    |\n*                                      +---------------------------+\n*                                 +---->      isDone() = true      |\n* +--------------------------+    |    |   isSuccess() = true      |\n* |        Uncompleted       |    |    +===========================+\n* +--------------------------+    |    | Completed with failure    |\n* |      isDone() = false    |    |    +---------------------------+\n* |   isSuccess() = false    |----+---->      isDone() = true      |\n* | isCancelled() = false    |    |    |       cause() = non-null  |\n* |       cause() = null     |    |    +===========================+\n* +--------------------------+    |    | Completed by cancellation |\n*                                 |    +---------------------------+\n*                                 +---->      isDone() = true      |\n*                                      | isCancelled() = true      |\n*                                      +---------------------------+\n```\n\nFuture对象有两种状态：未完成和已完成，其中已完成又有三种状态：成功、失败、用户取消。\n\n仔细看完上面的图并联系Future接口中的方法，你是不是也会和我有相同的疑问：Future接口中的方法都是getter方法而没有setter方法，也就是说这样实现的Future子类的状态是不可变的，如果我们想要变化，那该怎么办呢？Netty提供的解决方法是：使用可写的Future即Promise。\n\n# Netty-Promise\n\n```java\n// 标记异步操作结果为成功，如果已被设置（不管成功还是失败）则抛出异常IllegalStateException\nPromise<V> setSuccess(V result);\n// 同上，只是结果已被设置时返回False\nboolean trySuccess(V result);\n\nPromise<V> setFailure(Throwable cause);\nboolean tryFailure(Throwable cause);\n\n// 设置结果为不可取消，结果已被取消返回False\nboolean setUncancellable();\n```\n\nPromise接口继承自Future接口，它提供的setter方法与常见的setter方法大为不同。Promise从Uncompleted—>Completed的状态转变有且只能有一次，也就是说setSuccess和setFailure方法最多只会成功一个，此外，在setSuccess和setFailure方法中会通知注册到其上的监听者。\n\n## AbstractFuture\n  \n```java\n  @Override\npublic V get() throws InterruptedException, ExecutionException {\n    await();\n\n    Throwable cause = cause();\n    if (cause == null) {\n        return getNow();\n    }\n    if (cause instanceof CancellationException) {\n        throw (CancellationException) cause;\n    }\n    throw new ExecutionException(cause);\n}\n\n@Override\npublic V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException {\n    if (await(timeout, unit)) {\n        Throwable cause = cause();\n        if (cause == null) {\n            return getNow();\n        }\n        if (cause instanceof CancellationException) {\n            throw (CancellationException) cause;\n        }\n        throw new ExecutionException(cause);\n    }\n    throw new TimeoutException();\n}\n```\n其内部是重写了JDK中Future接口的get方法，内部通过调用await方法实现同步阻塞等待，Netty中的Future接口中的getNow非阻塞地返回异步结果，如果尚未完成返回null。\n\n## DefaultPromise\n1. 创建Promise的子类，实例创建后可以添加监听（保存在listeners中）或阻塞进行等待（waiters计数器，表示等待的线程数）；\n2. 封装Promise到待监听的Task中；\n3. 提交Task到线程执行器executor的队列中；\n4. 线程执行器executor获取Task，并在线程中执行Task，Task执行结束（成功、失败、取消）就会调用Promise中注册的所有listeners以及唤醒所有等待的线程；\n","tags":["Future Promise"]},{"title":"linux command","url":"/2019/04/17/linux-command/","content":"\n** {{ title }}：** <Excerpt in index | 首页摘要>\n总结一些linux命令\n<!-- more -->\n<The rest of contents | 余下全文>\n\n## linux 命令\n\n- 统计当前文件夹下文件的个数\n\n  ```shell\n  ls -l |grep \"^-\"|wc -l\n  ```\n\n- 统计当前文件夹下目录个数\n\n  ```shell\n  ls -l |grep \"^d\"|wc -l\n  ```\n\n- 压缩文件\n\n  ```shell\n  tar -czf jpg.tar.gz *.jpg\n  -c: 建立压缩档案\n  -x：解压\n  -t：查看内容\n  -r：向压缩归档文件末尾追加文件\n  -u：更新原压缩包中的文件\n  -f: 使用档案名字，切记，这个参数是最后一个参数，后面只能接档案名\n  -z：有gzip属性的\n  ```\n\n- 按每行切割文件,按大小切割\n\n  ```shell\n  split -d -num filename prefix\n  -d 代表以数字结尾命名\n  num 表示每个文件行数\n  filename 拆分的文件\n  prefix 拆分后文件命名前缀\n\n  切割为500m的文件\n  split -b 500m filename prefix\n  ```\n\n- grep查找文件中是否包含字符串\n\n  ```shell\n  grep 选项 pattern filename\n  -c,—count 只打印匹配的行数，不显示匹配的内容\n  -i，—ignore-case 忽略大小写差别\n  -l，—files-with-matches 打印匹配模板的文件清单\n  -n，—line-number 在匹配的行前面打印行号\n  ```\n\n- nohup 和 &后台运行\n\n  ```shell\n  nohup\n  不断地运行命令\n  &\n  在后台运行\n  一般两个一起用：nohup command &\n  查看运行的后台进程：jobs -l\n  ```\n\n- awk 分隔符\n\n  ```shell\n  awk  -F: '{print $1,$3,$6}' OFS=\"\\t\" /etc/passwd\n  -F指定输入分隔符\n  OFS指定输出分隔符\n  ```\n\n  查找两个文件不同的行\n\n  ```bash\n  awk '{ if( NR==FNR ){ a[$1]=1 } else { if( !($1 in a) ){ print \"diff:\",$1,$2} } }' file1 file2\n  ```\n\n- ulimit 用来限制系统用户对shell资源的访问 之前遇到 段错误 调试 生成core文件\n\n  ```shell\n  数据段长度：ulimit -d unlimited\n  最大内存大小：ulimit -m unlimited\n  堆栈大小：ulimit -s unlimited\n  产生core文件，就是程序运行发行段错误时的文件：\n  ulimit -c unlimited   \n  ```\n\n- lsof 查看端口\n  \n  ```shell\n  lsof -i:8080 -l\n  -l 查看pid\n  ```\n\n- ping & telnet\n  \n  ```shell\n  ping 192.168.0.1 -t 不停的测试192.168.0.1\n  telnet 192.168.0.1 80 可以测试端口\n  ```\n\n- time command\n\n  ```shell\n  time ./client.go 测试 client.go 运行时间\n  ```\n\n# 20190607 linux复习\n\n# 文件及目录\n\n## 创建和删除\n\n```shell\nmkdir\nrm\nrm -rf file/dir\nmv\ncp #dir: cp -r\n```\n\n## 目录切换\n\n```shell\ncd\ncd - # 切换到上一个工作目录\npwd #显示当前路径\n```\n\n## 列出目录\n\n```shell\nls\nll -trh\n```\n\n## find查找\n\n```shell\n#查找name为core* 并执行file显示详细信息\nfind ./ -name \"core*\" | xargs file\n#在find命令查找到的文件上执行命令\nfind -iname \"MyCProgram.c\" -exec md5sum {} \\;#\\转义\n#最近7天内被访问过的所有文件:\nfind . -atime -7 -type f -print\n```\n\n## 查看文件内容\n\n```shell\ncat -n #显示行号\nvim\nhead\ntail\nmore #按空格一页一页展示\ndiff file1 file2\n```\n\n## 权限修改\n\n```shell\nchmod 777 file # rwx权限\nchown #改变文件的拥有者\n```\n\n## 软链接/硬链接\n\n```shell\nln cc ccAgain #硬连接；删除一个，将仍能找到；\nln -s cc ccTo #符号链接(软链接)；删除源，另一个无法使用；（后面一个ccTo 为新建的文件）\n```\n\n# 文本处理\n\n## grep\n\n```shell\n#在多级目录中对文本递归搜索\ngrep \"class\" . -R -n\n#匹配多个模式\ngrep -e \"class1\" -e \"class2\" file\n#将日志中的所有带where条件的sql查找查找出来\ncat LOG.* | tr a-z A-Z | grep \"FROM \" | grep \"WHERE\" > b\n\n```\n\n## sort排序\n\n```shell\n-n 按数字进行排序 VS -d 按字典序进行排序\n-r 逆序排序\n-k N 指定按第N列排序\nsort -nrk 1 data.txt\n```\n\n## tr\n\n```shell\ncat text| tr '\\t' ' '  #制表符转空格\ncat file | tr -d '0-9'  #删除所有数字\ncat file | tr -c '0-9' #获取文件中所有数字\ncat file | tr -d -c '0-9 \\n'  #删除非数字数据\n```\n\n## awk\n\n```shell\ncat test.txt\n# I am Poe,my qq is 33794712\nawk -F '[ ,]+' '{print $3\" \"$7}' test.txt\n# Poe 33794712\n\nawk ' BEGIN{ statements } statements2 END{ statements } '\nawk 'BEGIN {count=0;print \"[start] user count is \",count} {count=count+1;print $0} END{print \"[end] user count is \",count}' passwd\n[start] user count is  0\nroot:x:0:0:root:/root:/bin/bash\n...................................................................\n[end] user count is  27\n```\n\n# 磁盘管理\n\n```shell\n#查看当前目录所占空间大小\ndu -sh \n#查看当前目录下所有子文件夹排序后的大小\ndu -sh `ls` | sort\n#查看磁盘空间 \ndf -h\n```\n\n\n\n# 进程\n\n```shell\n#查询正在运行的进程信息\n$ps -ef\n\n#eg:查询归属于用户colin115的进程\n$ps -ef | grep colin115\n$ps -lu colin115\n查询进程ID（适合只记得部分进程字段）\n\n$ps -ajx\n显示进程信息，并实时更新\n\n$top\n查看端口占用的进程状态：\n\nlsof -i:3306\n查看用户username的进程所打开的文件\n\n$lsof -u username\n查询init进程当前打开的文件\n\n$lsof -c init\n查询指定的进程ID(23295)打开的文件：\n\n$lsof -p 23295\n查询指定目录下被进程开启的文件（使用+D 递归目录）：\n\n$lsof +d mydir1/\n\ntop\nP：根据CPU使用百分比大小进行排序。\nM：根据驻留内存大小进行排序。\ni：使top不显示任何闲置或者僵死进程。\n```\n\n","tags":["linux"]},{"title":"为什么要重写equals和hashCode方法","url":"/2019/04/13/equals-hashcode/","content":"** {{ title }}：** <Excerpt in index | 首页摘要>\n当我们用HashMap存入自定义的类时，如果不重写这个自定义类的equals和hashCode方法，得到的结果会和我们预期的不一样。\n<!-- more -->\n<The rest of contents | 余下全文>\n\n# 为什么要重写equals和hashCode方法\n\n当我们用HashMap存入自定义的类时，如果不重写这个自定义类的equals和hashCode方法，得到的结果会和我们预期的不一样。我们来看WithoutHashCode.java这个例子。\n\n在其中的第2到第18行，我们定义了一个Key类；在其中的第3行定义了唯一的一个属性id。当前我们先注释掉第9行的equals方法和第16行的hashCode方法。\n\n```java\n1   import java.util.HashMap;\n2   class Key {\n3       private Integer id;\n4       public Integer getId()\n5   {return id; }\n6       public Key(Integer id)\n7   {this.id = id;  }\n8   //故意先注释掉equals和hashCode方法\n9   //  public boolean equals(Object o) {\n10  //      if (o == null || !(o instanceof Key))\n11  //      { return false; }\n12  //      else\n13  //      { return this.getId().equals(((Key) o).getId());}\n14  //  }\n15     \n16  //  public int hashCode()\n17  //  { return id.hashCode(); }\n18  }\n19 \n20  public class WithoutHashCode {\n21      public static void main(String[] args) {\n22          Key k1 = new Key(1);                                                  \n23          Key k2 = new Key(1);\n24          HashMap<Key,String> hm = new HashMap<Key,String>();\n25          hm.put(k1, \"Key with id is 1\");    \n26          System.out.println(hm.get(k2));    \n27      }\n28  }\n```\n\n在main函数里的第22和23行，我们定义了两个Key对象，它们的id都是1，就好比它们是两把相同的都能打开同一扇门的钥匙。\n\n在第24行里，我们通过泛型创建了一个HashMap对象。它的键部分可以存放Key类型的对象，值部分可以存储String类型的对象。\n\n在第25行里，我们通过put方法把k1和一串字符放入到hm里； 而在第26行，我们想用k2去从HashMap里得到值；这就好比我们想用k1这把钥匙来锁门，用k2来开门。这是符合逻辑的，但从当前结果看，26行的返回结果不是我们想象中的那个字符串，而是null。\n\n原因有两个—没有重写。第一是没有重写hashCode方法，第二是没有重写equals方法。\n\n当我们往HashMap里放k1时，首先会调用Key这个类的hashCode方法计算它的hash值，随后把k1放入hash值所指引的内存位置。\n\n关键是我们没有在Key里定义hashCode方法。这里调用的仍是Object类的hashCode方法（所有的类都是Object的子类），而Object类的hashCode方法返回的hash值其实是k1对象的内存地址（假设是1000）。\n\n如果我们随后是调用hm.get(k1)，那么我们会再次调用hashCode方法（还是返回k1的地址1000），随后根据得到的hash值，能很快地找到k1。\n\n但我们这里的代码是hm.get(k2)，当我们调用Object类的hashCode方法（因为Key里没定义）计算k2的hash值时，其实得到的是k2的内存地址（假设是2000）。由于k1和k2是两个不同的对象，所以它们的内存地址一定不会相同，也就是说它们的hash值一定不同，这就是我们无法用k2的hash值去拿k1的原因。\n\n当我们把第16和17行的hashCode方法的注释去掉后，会发现它是返回id属性的hashCode值，这里k1和k2的id都是1,所以它们的hash值是相等的。\n\n我们再来更正一下存k1和取k2的动作。存k1时，是根据它id的hash值，假设这里是100，把k1对象放入到对应的位置。而取k2时，是先计算它的hash值（由于k2的id也是1，这个值也是100），随后到这个位置去找。\n\n但结果会出乎我们意料：明明100号位置已经有k1，但第26行的输出结果依然是null。其原因就是没有重写Key对象的equals方法。\n\nHashMap是用链地址法来处理冲突，也就是说，在100号位置上，有可能存在着多个用链表形式存储的对象。它们通过hashCode方法返回的hash值都是100。\n\n当我们通过k2的hashCode到100号位置查找时，确实会得到k1。但k1有可能仅仅是和k2具有相同的hash值，但未必和k2相等（k1和k2两把钥匙未必能开同一扇门），这个时候，就需要调用Key对象的equals方法来判断两者是否相等了。\n\n由于我们在Key对象里没有定义equals方法，系统就不得不调用Object类的equals方法。由于Object的固有方法是根据两个对象的内存地址来判断，所以k1和k2一定不会相等，这就是为什么依然在26行通过hm.get(k2)依然得到null的原因。\n\n为了解决这个问题，我们需要打开第9到14行equals方法的注释。在这个方法里，只要两个对象都是Key类型，而且它们的id相等，它们就相等。","tags":["Java"]},{"title":"git 相关","url":"/2019/04/03/gitignore/","content":"** {{ title }}：** <Excerpt in index | 首页摘要>\n日常遇到的git问题\n<!-- more -->\n<The rest of contents | 余下全文>\n\n# gitignore\n\n**一定要养成在项目开始就创建.gitignore文件的习惯**\n\n突然心血来潮想把某些目录或文件加入忽略规则，按照上述方法定义后发现并未生效，原因是.gitignore只能忽略那些原来没有被track的文件，如果某些文件已经被纳入了版本管理中，则修改.gitignore是无效的。那么解决方法就是先把本地缓存删除（改变成未track状态），然后再提交：\n\n```shell\ngit rm -r --cached .\ngit add .\ngit commit -m 'update .gitignore'\n```\n\n# 递归删除指定目录下的.git文件\n\n子目录有.git 子目录下的文件上传不到git，需要删除 .git文件\n\n```shell\nfind . -name .git | xargs rm -fr\n```\n\n# 获取冲突文件列表\n\n需要一个冲突文件的简单列表\n\n```shell\ngit diff --name-only --diff-filter=U\n```\n\n# git中fatal: Authentication failed的问题\n> (20190429)今天帮一个女同学看这个。。一般是密码不对\n> windows环境下：控制面板->用户群组->凭据->找到git\n","tags":["Git"]},{"title":"JAVA JUC","url":"/2019/03/20/JUC/","content":"** {{ title }}：** <Excerpt in index | 首页摘要>\nimport java.util.concurrent ！看 java 高并发程序设计 做了一点总结\n<!-- more -->\n<The rest of contents | 余下全文>\n\n# import java.util.concurrent\n\n- 多种多线程控制方法\n- 线程池\n- JDK并发容器\n\n## 多线程控制方法\n\n### 重入锁（synchronized功能扩展）\n\n重入锁可以完全替代synchronized关键字，性能差距不大\n\n重入锁使用ReentrantLock类实现，与synchronize关键字相比，重入锁有显式的加锁释放锁，对逻辑控制更为灵活。\n\n此外还有一些高级功能。\n\n- 中断响应。对于synchronized来说，如果一个线程在等待锁，那么结果只有两种情况，要么它获得这把锁继续执行，要么它就保持等待。而使用重入锁，则提供另外一种可能，那就是线程可以中断，也就是在等待锁的过程中，程序可以根据需要取消对锁的请求。reentrantLock.lockInterruptibly();这个方法是一个可以对中断进行响应的锁申请动作。\n- 锁申请等待限时，给定一个时间，让线程自动放弃获取锁。我们可以使用trylock()方法进行一次限时的等待。\n- 公平锁。公平锁会按照时间的先后顺序，保证先到者先得。公平锁不会产生饥饿。实现公平锁要求系统维护一个有序队列，因此公平锁的实现成本比较高，性能相对低下。\n\n### 重入锁的搭档 condition条件\n\nwait()和notify()条件是和synchronized关键字合作使用的。\n\n而condition条件是与重入锁相关联的。\n\n和object.wait和object.notify方法一样，当线程使用condition.await()方法时，要求线程有相关的重入锁，在condition。await方法调用后，这个线程就会释放这把锁。同理，在condition.signal方法调用时，也要求线程获得相关的锁。\n\n### 允许多个线程同时访问 信号量\n\n广义上说，信号量是对锁的扩展。无论是内部锁synchronize还是重入锁reentrantlock，一次都只允许一个线程访问一个资源。而信号量却可以指定多个线程，同时访问某一个资源。\n\n```java\nfinal Semaphore semp = new Semaphore(5)\n```\n\n申明了一个包含5个许可的信号量，这就意味着同时可以有5个线程进入semp.acquire()～semp.release()之间的代码段。\n\n### ReadWriteLock 读写锁\n\n读写锁允许多个线程同时读，但写写操作和读写操作依然是需要相互等待和持有锁的。如果读操作远远大于写操作，那么读写锁可以发挥最大的功效。\n\n### CountDownLatch 倒计时器\n\n倒计时器是一个非常实用的多线程控制工具类。这个工具常用来控制线程等待，它可以让某一个线程等待直到倒计时结束，在开始执行。\n\n```java\nstatic final CountDownLatch end = new CountDownLatch(10)\n```\n\n生成了一个CountDownLatch的实例，计数数量为10，这代表着需要10个线程完成任务，等待在CountDownLatch上的线程才能继续执行。\n\n```java\nCountDownLatch.countdown()\n```\n\n在线程内调用上面的方法，通知CountDownLatch，一个线程已经完成了任务，倒计时器可以减1.\n\n```java\nCountDownLatch.await()\n```\n\n调用该方法的线程需要等待所有10个线程任务全部完成，待10个任务全部完成后，该线程才能继续执行。\n\n### CyclicBarrier 循环栅栏\n\nCyclicBarrier是另外一种多线程并发控制使用工具。和CountDownLatch非常相似，它可以实现线程间的计数等待，但它的功能比CountDownLatch更加复杂且强大。\n\n在CyclicBarrier中，我们将计数器设为10，那么凑齐第一批10个线程后，计数器归零，然后接着凑齐下一批10个线程。\n\n比CountDownLatch略微强大点，CyclicBarrier可以接受一参数为barrierAction，就是当计数器完成一次计数后，系统会执行的动作。\n\n```java\nCyclicBarrier.awiat()\n```\n\n每个线程调用该方法，表示等待N个线程，当一批线程完成后，才会继续执行下面的任务。\n\nCyclicBarrier可能会有两个异常，InterruptedException和BrokenBarrierException。\n\n### 线程阻塞工具类 LockSupport\n\nLockSupport可以在线程内任意位置让线程阻塞。\n\n- 和Thread.suspend()相比，它弥补了由于resume()发生在suspend()之前，导致线程无法继续执行，并可能产生死锁的情况。\n- 和object.wait()相比，它不需要先获得某个对象的锁，也不会抛出InterruptedException异常。\n\nLockSupport的静态方法park()可以阻塞当前线程，类似的还有parkNanos()、partUntil()等，他们实现了限时的等待。\n\nLockSupport使用了类似于（二元）信号量的机制。它为每个线程准备了一个许可，默认为0。如果许可可用，那么park函数会立即返回，并且消费这个许可（也就是继续执行）；如果不可用，那么会挂起。而unpark会使得一个许可变为可用。\n\n处于park挂起的线程不会像suspend那样还给出一个令人费解的Runnable状态。它会非常明确的给出waiting（parking）。\n\n\n\n\n\n## 线程复用 线程池\n\n为了避免频繁地创建和销毁线程，我们可以创建线程池对线程进行复用。\n\n线程池中，总有那么几个活跃的线程，当你需要使用线程时，从池子中随便拿一个空闲线程，当完成工作后，并不急着关闭线程，而是将这个线程放回池子，方便其他人使用。使用线程池后，创建线程变成了从池子里获得空闲线程，销毁线程变成了向池子归还线程。\n\nJDK Executor框架提供了各种类型的线程池，主要有以下工厂方法。\n\n```java\npublic static ExectorService newFixedThreadPool(int nThreads)\npublic static ExectorService newSingleThreadExecutor()\npublic static ExectorService newCachedThreadPool()\npublic static ScheduleExecutorService newSingleThreadScheduledExecutor()\npublic static ScheduleExecutorService newScheduleThreadPool(int corePoolSize)\n```\n\n以上方法分别返回具有不同特性的线程池。\n\n- newFixedThreadPool(int nThreads) 该方法返回一个固定线程数量的线程池。当有一个新任务提交时，线程中若有空闲线程，则立即执行；若没有，则新的任务会被暂存到一个任务队列，待线程空闲时，便处理在任务队列里的任务。\n- newSingleThreadExecutor() 该方法返回一个只有一个线程的线程池。若多余一个任务被提交到该线程池，任务会被保存到一个任务队列中，待线程空闲，按FIFO的顺序执行队列中的任务。\n- newCachedThreadPool() 该方法返回一个可以根据实际情况调整线程数量的线程池。线程池中的线程数量不确定，但若有空闲线程可以复用，则会优先使用可以复用的线程。若所有的线程都在工作，又有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行复用。\n- newSingleThreadScheduledExecutor() 该方法返回一个ScheduleExecutorService对象，线程池大小为1。ScheduleExecutorService接口在ExecutorService接口之上扩展了在给定时间执行某任务的功能。如在某个固定的延时之后执行，或在周期性执行某个任务。\n- newScheduleThreadPool(int corePoolSize) 该方法返回一个ScheduleExecutorService对象，但该线程池可以指定线程数量。\n\n### 核心线程池的内部实现\n\n```java\n    public ThreadPoolExecutor(int corePoolSize,\n                              int maximumPoolSize,\n                              long keepAliveTime,\n                              TimeUnit unit,\n                              BlockingQueue<Runnable> workQueue,\n                              ThreadFactory threadFactory,\n                              RejectedExecutionHandler handler) {\n        if (corePoolSize < 0 ||\n            maximumPoolSize <= 0 ||\n            maximumPoolSize < corePoolSize ||\n            keepAliveTime < 0)\n            throw new IllegalArgumentException();\n        if (workQueue == null || threadFactory == null || handler == null)\n            throw new NullPointerException();\n        this.corePoolSize = corePoolSize;\n        this.maximumPoolSize = maximumPoolSize;\n        this.workQueue = workQueue;\n        this.keepAliveTime = unit.toNanos(keepAliveTime);\n        this.threadFactory = threadFactory;\n        this.handler = handler;\n    }\n```\n\n函数参数含义如下：\n\n```java\nint corePoolSize,\t//指定了线程池中的线程数量\nint maximumPoolSize,\t//指定了线程池中的最大线程数量\nlong keepAliveTime,\t//当线程池线程超过了corepoolsize时， 多余的空闲线程存活时间\nTimeUnit unit,\t//keepalivetime的单位\nBlockingQueue<Runnable> workQueue,\t//任务队列，被提交但尚未被执行的任务\nThreadFactory threadFactory,\t//线程工厂，用于创建线程，一般用默认的即可\nRejectedExecutionHandler handler\t//拒绝策略，当任务太多来不及更新，如何拒绝任务\n```\n\n对workQueue和handler进行详细说明。\n\n参数workQueue值被提交但尚未被执行的任务队列，它是一个BlockingQueue接口的对象，仅用于存放runable对象。根据队列功能分类，可使用一下几种BlockingQueue。\n\n- 直接提交的队列。该功能由SynchronousQueue对象提供。SynchronousQueue是一个特殊的BLockingQueue。SynchronousQueue没有容量，提交的任务不会被真实的保存，而总是将新任务提交给线程执行。如果没有空闲的线程，则尝试创建新的线程，如果线程数量达到了最大值，则执行拒绝策略。\n\n- 有界的任务队列。有界的任务队列可以使用ArrayBlockingQueue实现。\n\n  ```java\n  public ArrayBlockingQueue(int capacity)\n  ```\n\n  当使用有界的任务队列时，若有新的任务需要执行，如果线程池的线程数量小于corePoolSize，则会优先创建新的线程，若大于，则会将新任务加入等待队列。若等待队列已满，无法加入，则在总线程数不大于maximumPoolSize的前提下，创建新的线程执行任务。若大于maximumPoolSize，执行拒绝策略。可见，当任务队列装满时，才可能将线程数量提升到corePoolSize以上。\n\n- 无界的任务队列。无界的任务队列可以通过LinkedBlockingQueue类实现。除非系统资源耗尽，否则无界的任务队列不会出现任务入队失败的情况。当有新的任务到来，系统的线程数小于corePoolSize时，线程池会产生新的线程执行任务，但当线程数达到corePoolSize后，线程数不会增加，任务直接进入队列等待。\n\n- 优先任务队列。优先任务对立是带有执行优先级的队列。它通过PriorityBlockingQueue实现，可以控制任务的执行先后顺序。它是一个特殊的无界队列，根据任务自身的优先级来先后执行。\n\n### 拒绝策略\n\nJDK内置了四种拒绝策略：\n\n- AbortPolicy：该策略会直接抛出异常，阻止系统正常工作\n- CallerRunsPolicy：只要线程池未关闭，该策略直接在调用者线程中，运行当前被丢弃的任务\n- DiscardOldestPolicy：丢弃最老的一个任务，也就是即将被执行的一个任务，并尝试再次提交当前任务\n- DiscardPolicy：默默地丢弃无法处理的任务\n\n可以自定义扩展RejectExecutionHandler接口。\n\n### 自定义线程创建 ThreadFactory\n\n线程从何而来？答案就是ThreadFactory。\n\nThreadFactory是一个接口，它只有一个方法，用来创建线程：\n\n```java\nThread newThread(Runnable r);\n```\n\n### 扩展线程池\n\n情景：我们想监控每个任务执行开始和结束的时间\n\nThreadPoolExecutor是一个可扩展的线程池。它提供了beforeExecute()和afterExecute()、terminated()三个接口对线程池进行控制。\n\n### 分而治之 fork/join框架\n\n对于线程池的优化，提交的任务和线程数量并不是一对一的关系。在绝大多数情况下，一个物理线程实际上是需要处理多个逻辑任务的。因此，每个线程必然需要拥有一个任务队列。因此，在实际执行过程中，可能遇到线程A已经把自己的任务做完了，而线程B还有一堆任务等着处理。此时，线程A就会帮助线程B，从线程B的任务队列中拿一个任务过来处理，尽可能地达到平衡。注意：一个线程试图帮助别人时，总是从任务队列的底部开始拿数据，而线程试图执行自己的任务时，则是从相反的顶部拿，避免数据竞争。\n\n```java\npublic <T> ForkJoinTask<T> submit(ForkJoinTask<T> task) {\n        return externalSubmit(task);\n    }\n```\n\nForkJoinTask有两个子类，RecursiveAction和RecursiveTask，分别表示无返回值和有返回值的任务。\n一个文本搜索的demo\n\n```java\n// Document类生成一篇numLines行，numWords列的文章\npublic class Document {\n\n    private String words[] = {\"the\", \"hello\", \"goodbye\", \"packet\", \"java\", \"thread\", \"pool\", \"random\", \"class\", \"main\"};\n\n    public String[][] generateDocument(int numLines, int numWords) {\n        String document[][] = new String[numLines][numWords];\n        Random random = new Random();\n\n        for (int i = 0; i < numLines; i++) {\n            for (int j = 0; j < numWords; j++) {\n                int index = random.nextInt(words.length);\n                document[i][j] = words[index];\n            }\n        }\n\n        return document;\n    }\n\n}\n\n// DocumentTask类，定义大任务分解规则、子任务计算规则\npublic class DocumentTask extends RecursiveTask<Integer> {\n\n    private String document[][];\n    private int start, end;\n    private String word;\n\n    public DocumentTask(String document[][], int start, int end, String word) {\n        this.document = document;\n        this.start = start;\n        this.end = end;\n        this.word = word;\n    }\n\n    // 重点：覆盖compute()方法，完成任务分解，任务计算\n    @Override\n    protected Integer compute() {\n        int result;\n        if (end - start < 10) {    // 子任务不需要再分解，直接计算\n            result = processLines(document, start, end, word);\n        } else {\n            int mid = (start + end) / 2;    // 大任务一分为二\n            DocumentTask task1 = new DocumentTask(document, start, mid, word);\n            DocumentTask task2 = new DocumentTask(document, mid, end, word);\n            task1.fork();    // 分解的任务一，执行\n            task2.fork();    // 分解的任务二，执行\n            result = task1.join() + task2.join();    // 获取执行结果\n        }\n        return result;\n    }\n\n    private Integer processLines(String[][] document, int start, int end, String word) {\n        int counter = 0;\n        for (int i = start; i < end; i++) {\n            String[] line = document[i];\n            for (int j = 0; j < line.length; ++j) {\n                if (line[j].equals(word)) {\n                    counter++;\n                }\n            }\n        }\n        return counter;\n    }\n\n}\n\n// ForkJoinPool，负责任务执行\npublic class Main {\n\n    public static void main(String[] args) {\n        Document mock = new Document();\n        String[][] document = mock.generateDocument(100, 1000);\n\n        DocumentTask task = new DocumentTask(document, 0, 100, \"the\");\n\n        ForkJoinPool pool = new ForkJoinPool();\n        pool.submit(task);\n\n        try {\n            System.out.printf(\"Main: The word appears %d in the document\\n\", task.get());\n        } catch (InterruptedException | ExecutionException e) {\n            e.printStackTrace();\n        }\n    }\n\n}\n```\n\n## JDK并发容器\n\n- ConcurrentHashmap 线程安全的hashmap\n- CopyOnWriteArrayList 在读多写少的情况下，性能好\n- ConcurrentLinkedQueue 高效的并发队列，线程安全LinkedList\n- BlockingQueue 这是一个接口，表示阻塞队列，JDK使用数组、链表等方式实现了这个接口\n- ConcurrentSkipListMap 跳表的实现\n\n# 锁的优化及注意事项\n\n## 有助于优化锁的几点建议\n\n- 减小锁的持有时间\n- 减小锁的粒度\n- 读写分离锁来替换独占锁\n- 锁分离\n- 锁粗化","tags":["多线程,JUC"]},{"title":"Redis 相关","url":"/2019/03/20/Redis/","content":"** {{ title }}：** <Excerpt in index | 首页摘要>\n前几天面试准备的Redis\n<!-- more -->\n<The rest of contents | 余下全文>\n# Redis\n\n## Redis与Memcached的区别与比较\n\n  1 、Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，zset，hash等数据结构的存储。memcache支持简单的数据类型，String。\n\n  2 、Redis支持数据的备份，即master-slave模式的数据备份。\n\n  3 、Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而Memecache把数据全部存在内存之中\n\n  4、 redis的速度比memcached快很多\n\n  5、Memcached是多线程，非阻塞IO复用的网络模型；Redis使用单线程的IO复用模型。\n\n## Redis常见的数据结构\n\n  String\n\n  String数据结构是简单的key-value类型，value其实不仅可以是String，也可以是数字。  常规key-value缓存应用;常规计数：微博数，粉丝数等。\n\n  Hash\n\n  Hash是一个string类型的field和value的映射表，hash特别适合用于存储对象。 比如我们可以Hash数据结构来存储用户信息，商品信息等等。\n\n  List\n\n  list就是链表，Redis list的应用场景非常多，也是Redis最重要的数据结构之一，比如微博的关注列表，粉丝列表，最新消息排行等功能都可以用Redis的list结构来实现。\n\n  Set\n\n  set对外提供的功能与list类似是一个列表的功能，特殊之处在于set是可以自动排重的。\n\n  在微博应用中，可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。Redis可以非常方便的实现如共同关注、共同喜好、二度好友等功能。\n\n  SortedSet\n\n  和set相比，sorted set增加了一个权重参数score，使得集合中的元素能够按score进行有序排列。举例： 在直播系统中，实时排行信息包含直播间在线用户列表，各种礼物排行榜，弹幕消息（可以理解为按消息维度的消息排行榜）等信息，适合使用Redis中的SortedSet结构进行存储。\n\n\n*********\n**从宏观角度回顾一下Redis实现高可用相关的技术。它们包括：持久化、复制、哨兵和集群，其主要作用和解决的问题是**：\n  - 持久化：持久化是最简单的高可用方法(有时甚至不被归为高可用的手段)，主要作用是数据备份，即将数据存储在硬盘，保证数据不会因进程退出而丢失。\n  - 复制：复制是高可用Redis的基础，哨兵和集群都是在复制基础上实现高可用的。复制主要实现了数据的多机备份，以及对于读操作的负载均衡和简单的故障恢复。缺陷：故障恢复无法自动化；写操作无法负载均衡；存储能力受到单机的限制。\n  - 哨兵：在复制的基础上，哨兵实现了自动化的故障恢复。缺陷：写操作无法负载均衡；存储能力受到单机的限制。\n  - 集群：通过集群，Redis解决了写操作无法负载均衡，以及存储能力受到单机限制的问题，实现了较为完善的高可用方案。\n******\n\n## redis有哪些数据淘汰策略？？？\n\n  volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰 \n\n  volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰 \n\n  volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 \n\n  allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰 \n\n  allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 \n\n  no-enviction（驱逐）：禁止驱逐数据\n\n  *默认的内存策略是noeviction，在Redis中LRU算法是一个近似算法，默认情况下，Redis随机挑选5个键，并且从中选取一个最近最久未使用的key进行淘汰，在配置文件中可以通过maxmemory-samples的值来设置redis需要检查key的个数,但是栓查的越多，耗费的时间也就越久,但是结构越精确(也就是Redis从内存中淘汰的对象未使用的时间也就越久~),设置多少，综合权衡吧~~~*\n\n## Redis 持久化\n\nredis 支持两种持久化方式，一种是 Snapshotting（快照）也是默认方式，另一种是 Append-only file（缩写 aof）的方式。\n\n快照是默认的持久化方式。这种方式是就是将内存中数据以快照的方式写入到二进制文件中,默认的文件名为dump.rdb。可以通过配置设置自动做快照持久化的方式。\n\n```\n1.redis 调用 fork,现在有了子进程和父进程。\n2. 父进程继续处理 client 请求，子进程负责将内存内容写入到临时文件。由于 os 的实时复制机制（ copy on write)父子进程会共享相同的物理页面，当父进程处理写请求时 os 会为父进程要修改的页面创建副本，而不是写共享的页面。所以子进程地址空间内的数据是 fork时刻整个数据库的一个快照。\n3.当子进程将快照写入临时文件完毕后，用临时文件替换原来的快照文件，然后子进程退出。client 也可以使用 save 或者 bgsave 命令通知 redis 做一次快照持久化。 save 操作是在主线程中保存快照的，由于 redis 是用一个主线程来处理所有 client 的请求，这种方式会阻塞所有client 请求。所以不推荐使用。另一点需要注意的是，每次快照持久化都是将内存数据完整写入到磁盘一次，并不是增量的只同步变更数据。如果数据量大的话，而且写操作比较多，必然会引起大量的磁盘 io 操作，可能会严重影响性能。\n```\n\n由于快照方式是在一定间隔时间做一次的，所以如果 redis 意外 down 掉的话，就会丢失最后一次快照后的所有修改。\n\n如果应用要求不能丢失任何修改的话，可以采用 aof 持久化方式。下面介绍 Append-only file:aof 比快照方式有更好的持久化性，是由于在使用 aof 持久化方式时,redis 会将每一个收到的写命令都通过 write 函数追加到文件中(默认是 appendonly.aof)。当 redis 重启时会通过重新执行文件中保存的写命令来在内存中重建整个数据库的内容。当然由于 os 会在内核中缓存 write 做的修改，所以可能不是立即写到磁盘上。这样 aof 方式的持久化也还是有可能会丢失部分修改。不过我们可以通过配置文件告诉 redis 我们想要通过 fsync 函数强制 os 写入到磁盘的时机。\n\n## 主从复制\n\n全量复制：\n\nRedis全量复制一般发生在Slave初始化阶段，这时Slave需要将Master上的所有数据都复制一份。具体步骤如下： \n\n　　1）从服务器连接主服务器，发送SYNC命令； \n\n　　2）主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执行的所有写命令； \n\n　　3）主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令； \n\n　　4）从服务器收到快照文件后丢弃所有旧数据，载入收到的快照； \n\n　　5）主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令； \n\n　　6）从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令； \n\n增量同步：\n\nRedis增量复制是指Slave初始化后开始正常工作时主服务器发生的写操作同步到从服务器的过程。 \n\n增量复制的过程主要是主服务器每执行一个写命令就会向从服务器发送相同的写命令，从服务器接收并执行收到的写命令。\n\n主从复制策略：\n\n主从刚刚连接的时候，进行全量同步；全同步结束后，进行增量同步。当然，如果有需要，slave 在任何时候都可以发起全量同步。redis 策略是，无论如何，首先会尝试进行增量同步，如不成功，要求从机进行全量同步。\n\n## 哨兵\n\n关于哨兵的原理，关键是了解以下几个概念。\n\n（1）定时任务：每个哨兵节点维护了3个定时任务。定时任务的功能分别如下：通过向主从节点发送info命令获取最新的主从结构；通过发布订阅功能获取其他哨兵节点的信息；通过向其他节点发送ping命令进行心跳检测，判断是否下线。\n\n（2）主观下线：在心跳检测的定时任务中，如果其他节点超过一定时间没有回复，哨兵节点就会将其进行主观下线。顾名思义，主观下线的意思是一个哨兵节点“主观地”判断下线；与主观下线相对应的是客观下线。\n\n（3）客观下线：哨兵节点在对主节点进行主观下线后，会通过sentinel is-master-down-by-addr命令询问其他哨兵节点该主节点的状态；如果判断主节点下线的哨兵数量达到一定数值，则对该主节点进行客观下线。\n\n**需要特别注意的是，客观下线是主节点才有的概念；如果从节点和哨兵节点发生故障，被哨兵主观下线后，不会再有后续的客观下线和故障转移操作。**\n\n（4）选举领导者哨兵节点：当主节点被判断客观下线以后，各个哨兵节点会进行协商，选举出一个领导者哨兵节点，并由该领导者节点对其进行故障转移操作。\n\n监视该主节点的所有哨兵都有可能被选为领导者，选举使用的算法是Raft算法；Raft算法的基本思路是先到先得：即在一轮选举中，哨兵A向B发送成为领导者的申请，如果B没有同意过其他哨兵，则会同意A成为领导者。选举的具体过程这里不做详细描述，一般来说，哨兵选择的过程很快，谁先完成客观下线，一般就能成为领导者。\n\n（5）故障转移：选举出的领导者哨兵，开始进行故障转移操作，该操作大体可以分为3个步骤：\n\n- 在从节点中选择新的主节点：选择的原则是，首先过滤掉不健康的从节点；然后选择优先级最高的从节点(由slave-priority指定)；如果优先级无法区分，则选择复制偏移量最大的从节点；如果仍无法区分，则选择runid最小的从节点。\n- 更新主从状态：通过slaveof no one命令，让选出来的从节点成为主节点；并通过slaveof命令让其他节点成为其从节点。\n- 将已经下线的主节点(即6379)设置为新的主节点的从节点，当6379重新上线后，它会成为新的主节点的从节点。","tags":["Redis"]},{"title":"分布式的一些算法","url":"/2019/03/20/distribution/","content":"** {{ title }}：** <Excerpt in index | 首页摘要>\n入门分布式，看了一些分布式的算法……\n<!-- more -->\n<The rest of contents | 余下全文>\n# CAP\n\nCAP理论：一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项。\n\n### Consistency 一致性\n\n一致性指“`all nodes see the same data at the same time`”，即更新操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致，所以，一致性，说的就是数据一致性。\n\n### Availability 可用性\n\n可用性指“`Reads and writes always succeed`”，即服务一直可用，而且是正常响应时间。\n\n### Partition Tolerance分区容错性\n\n分区容错性指“`the system continues to operate despite arbitrary message loss or failure of part of the system`”，即分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务。\n\n# BASE\n\nBASE是指基本可用（Basically Available）、软状态（ Soft State）、最终一致性（ Eventual Consistency）。\n\n### 基本可用（Basically Available）\n\n基本可用是指分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用。\n\n电商大促时，为了应对访问量激增，部分用户可能会被引导到降级页面，服务层也可能只提供降级服务。这就是损失部分可用性的体现。\n\n### 软状态（ Soft State）\n\n软状态是指允许系统存在中间状态，而该中间状态不会影响系统整体可用性。分布式存储中一般一份数据至少会有三个副本，允许不同节点间副本同步的延时就是软状态的体现。mysql replication的异步复制也是一种体现。\n\n### 最终一致性（ Eventual Consistency）\n\n最终一致性是指系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。弱一致性和强一致性相反，最终一致性是弱一致性的一种特殊情况。\n\n# 2PC\n\n二阶段提交协议主要分为来个阶段：准备阶段和提交阶段。\n\n在日常生活中其实是有很多事都是这种二阶段提交的，比如西方婚礼中就经常出现这种场景：\n\n> 牧师：”你愿意娶这个女人吗?爱她、忠诚于她，无论她贫困、患病或者残疾，直至死亡。Doyou(你愿意吗)?”\n>\n> 新郎：”Ido(我愿意)!”\n>\n> 牧师：”你愿意嫁给这个男人吗?爱他、忠诚于他，无论他贫困、患病或者残疾，直至死亡。Doyou(你愿意吗)?”\n>\n> 新娘：”Ido(我愿意)!”\n>\n> 牧师：现在请你们面向对方，握住对方的双手，作为妻子和丈夫向对方宣告誓言。\n>\n> 新郎：我——某某某，全心全意娶你做我的妻子，无论是顺境或逆境，富裕或贫穷，健康或疾病，快乐或忧愁，我都将毫无保留地爱你，我将努力去理解你，完完全全信任你。我们将成为一个整体，互为彼此的一部分，我们将一起面对人生的一切，去分享我们的梦想，作为平等的忠实伴侣，度过今后的一生。\n>\n> 新娘：我全心全意嫁给你作为你的妻子，无论是顺境或逆境，富裕或贫穷，健康或疾病，快乐或忧愁，我都将毫无保留的爱你，我将努力去理解你，完完全全信任你，我们将成为一个整体，互为彼此的一部分，我们将一起面对人生的一切，去分享我们的梦想，作为平等的忠实伴侣，度过今后的一生。\n\n首先协调者（牧师）会询问两个参与者（二位新人）是否能执行事务提交操作（愿意结婚）。如果两个参与者能够执行事务的提交，先执行事务操作，然后返回YES，如果没有成功执行事务操作，就返回NO。\n\n当协调者接收到所有的参与者的反馈之后，开始进入事务提交阶段。如果所有参与者都返回YES，那就发送COMMIT请求，如果有一个人返回NO，那就返送roolback请求。\n\n- 2PC协议中，如果出现协调者和参与者都挂了的情况，有可能导致数据不一致。\n\n第二阶段协调者和参与者挂了，挂了的这个参与者在挂之前已经执行了操作。但是由于他挂了，没有人知道他执行了什么操作。\n\n- 这种情况下，新的协调者被选出来之后，如果他想负起协调者的责任的话他就只能按照之前那种情况来执行commit或者roolback操作。这样新的协调者和所有没挂掉的参与者就保持了数据的一致性，我们假定他们执行了commit。但是，这个时候，那个挂掉的参与者恢复了怎么办，因为他之前已经执行完了之前的事务，如果他执行的是commit那还好，和其他的机器保持一致了，万一他执行的是roolback操作那？这不就导致数据的不一致性了么？虽然这个时候可以再通过手段让他和协调者通信，再想办法把数据搞成一致的，但是，这段时间内他的数据状态已经是不一致的了！\n\n------\n\n# 3PC\n\n3PC最关键要解决的就是协调者和参与者同时挂掉的问题，所以3PC把2PC的准备阶段再次一分为二，这样三阶段提交就有`CanCommit`、`PreCommit`、`DoCommit`三个阶段。在第一阶段，只是询问所有参与者是否可可以执行事务操作，并不在本阶段执行事务操作。当协调者收到所有的参与者都返回YES时，在第二阶段才执行事务操作，然后在第三阶段在执行commit或者rollback。\n\n这里再举一个生活中类似三阶段提交的例子：\n\n> 班长要组织全班同学聚餐，由于大家毕业多年，所以要逐个打电话敲定时间，时间初定10.1日。然后开始逐个打电话。\n>\n> 班长：小A，我们想定在10.1号聚会，你有时间嘛？有时间你就说YES，没有你就说NO，然后我还会再去问其他人，具体时间地点我会再通知你，这段时间你可先去干你自己的事儿，不用一直等着我。（**协调者询问事务是否可以执行，这一步不会锁定资源**）\n>\n> 小A：好的，我有时间。（**参与者反馈**）\n>\n> 班长：小B，我们想定在10.1号聚会……不用一直等我。\n>\n> 班长收集完大家的时间情况了，一看大家都有时间，那么就再次通知大家。（**协调者接收到所有YES指令**）\n>\n> 班长：小A，我们确定了10.1号聚餐，你要把这一天的时间空出来，这一天你不能再安排其他的事儿了。然后我会逐个通知其他同学，通知完之后我会再来和你确认一下，还有啊，如果我没有特意给你打电话，你就10.1号那天来聚餐就行了。对了，你确定能来是吧？（**协调者发送事务执行指令，这一步锁住资源。如果由于网络原因参与者在后面没有收到协调者的命令，他也会执行commit**）\n>\n> 小A顺手在自己的日历上把10.1号这一天圈上了，然后跟班长说，我可以去。（**参与者执行事务操作，反馈状态**）\n>\n> 班长：小B，我们觉得了10.1号聚餐……你就10.1号那天来聚餐就行了。\n>\n> 班长通知完一圈之后。所有同学都跟他说：”我已经把10.1号这天空出来了”。于是，他在10.1号这一天又挨个打了一遍电话告诉他们：嘿，现在你们可以出门拉。。。。（**协调者收到所有参与者的ACK响应，通知所有参与者执行事务的commit**）\n>\n> 小A，小B：我已经出门拉。（**执行commit操作，反馈状态**）\n\n- 3PC为什么比2PC好？？\n\n**简单概括一下就是，如果挂掉的那台机器已经执行了commit，那么协调者可以从所有未挂掉的参与者的状态中分析出来，并执行commit。如果挂掉的那个参与者执行了rollback，那么协调者和其他的参与者执行的肯定也是rollback操作。**\n\n- 3PC的问题\n\n在doCommit阶段，如果参与者无法及时接收到来自协调者的doCommit或者rebort请求时，会在等待超时之后，会继续进行事务的提交。所以，由于网络原因，协调者发送的abort响应没有及时被参与者接收到，那么参与者在等待超时之后执行了commit操作。这样就和其他接到abort命令并执行回滚的参与者之间存在数据不一致的情况。\n\n# PAXOS\n\n解决的问题：在一个可能发生异常的分布式系统中如何就某个值达成一致，让整个集群的节点对某个值的变更达成一致\n\n任何一个节点都可以提出要修改某个数据的提案,是否通过这个提案取决于这个集群中是否有超过半数的节点同意（所以节点数总是单数）—— 版本标记。虽然一致性，但是只能对一个操作进行操作啊？？\n\n当一个Server接收到比当前版本号小的提案时，则拒绝。当收到比当前大的版本号的提案时，则锁定资源，进行修改，返回OK.   也就是说收到超过一半的最大版本的提案才算成功。\n\n核心思想：\n\n在抢占式访问权的基础上引入多个acceptor，也就是说当一个版本号更大的提案可以剥夺版本号已经获取的锁。\n\n后者认同前者的原则：\n\n> 在肯定旧epoch 无法生成确定性取值时，新的 epoch 会提交自己的valu\n>\n> 一旦 旧epoch形成确定性取值，新的 epoch肯定可以获取到此取值，并且会认同此取值，不会被破坏。\n\n# ZAB \n\n定义：原子广播协议 ZAB 是一致性协议，Zookeeper 把其作为数据一致性的算法。ZAB 是在 Paxos 算法基础上进行扩展而来的。Zookeeper 使用单一主进程 Leader用于处理客户端所有事务请求，采用 ZAB 协议将服务器状态以事务形式广播到所有 Follower 上，由于事务间可能存在着依赖关系，ZAB协议保证 Leader 广播的变更序列被顺序的处理，一个状态被处理那么它所依赖的状态也已经提前被处理\n\n核心思想：保证任意时刻只有一个节点是Leader，所有更新事务由Leader发起去更新所有副本 Follower，更新时用的是 两段提交协议，只要多数节点 prepare 成功，就通知他们commit。各个follower 要按当初 leader 让他们 prepare 的顺序来 apply 事务\n\n协议状态\n\nLooking:系统刚启动时 或者 Leader 崩溃后正处于选举状态\n\nFollowing：Follower 节点所处的状态，Follower与 Leader处于数据同步状态\n\nLeading：Leader 所处状态，当前集群中有一个 Leader 为主进程\n\nZooKeeper启动时所有节点初始状态为Looking，这时集群会尝试选举出一个Leader节点，选举出的Leader节点切换为Leading状态；当节点发现集群中已经选举出Leader则该节点会切换到Following状态，然后和Leader节点保持同步；当Follower节点与Leader失去联系时Follower节点则会切换到Looking状态，开始新一轮选举；在ZooKeeper的整个生命周期中每个节点都会在Looking、Following、Leading状态间不断转换。\n\n\n\n选举出Leader节点后 ZAB 进入原子广播阶段，这时Leader为和自己同步每个节点 Follower 创建一个操作序列，一个时期一个 Follower 只能和一个Leader保持同步\n\n# Raft\n\n在Raft中，任何时候一个服务器可以扮演下面角色之一：\n\n1. Leader: 处理所有客户端交互，日志复制等，一般一次只有一个Leader.\n2. Follower: 类似选民，完全被动\n3. Candidate候选人: 类似Proposer律师，可以被选为一个新的领导人。\n\nRaft阶段分为两个，首先是选举过程，然后在选举出来的领导人带领进行正常操作，比如日志复制等。\n\n- 任何一个服务器都可以成为一个候选者Candidate，它向其他服务器Follower发出要求选举自己的请求：\n- 其他服务器同意了，发出OK。注意如果在这个过程中，有一个Follower宕机，没有收到请求选举的要求，因此候选者可以自己选自己，只要达到N/2 + 1 的大多数票，候选人还是可以成为Leader的。\n- 这样这个候选者就成为了Leader领导人，它可以向选民也就是Follower们发出指令，比如进行日志复制。\n- 以后通过心跳进行日志复制的通知\n- 如果一旦这个Leader当机崩溃了，那么Follower中有一个成为候选者，发出邀票选举。\n- Follower同意后，其成为Leader，继续承担日志复制等指导工作：\n\nSplite Vote是因为如果同时有两个候选人向大家邀票，这时通过类似加时赛来解决，两个候选者在一段timeout比如300ms互相不服气的等待以后，因为双方得到的票数是一样的，一半对一半，那么在300ms以后，再由这两个候选者发出邀票，这时同时的概率大大降低，那么首先发出邀票的的候选者得到了大多数同意，成为领导者Leader，而另外一个候选者后来发出邀票时，那些Follower选民已经投票给第一个候选者，不能再投票给它，它就成为落选者了，最后这个落选者也成为普通Follower一员了。\n\nhttps://blog.csdn.net/lxlmycsdnfree/article/details/78984752\n\n*********\n\n2019/05/14 Raft\n\nraft将系统的一致性（consistency）抽象为每个Node的状态机（stat machine）一致，raft假设每个Node如果初始状态一致，并且每个Node的状态机执行相同的操作序列，那么这些状态机的最终状态将保持一致。这里的状态机看起来比较抽象，可以简单给个例子，比如KV系统，状态机在这里就代表了这个KV系统的所存储的key-value对，状态机一致即要求所有Node上的key集合一样，并且key相同的的value也要一样，并且没有那台机器多一些key或者少一些key。操作序列在这里可以抽象为两种，设置某个key或者删除某个key。\n\n下图是raft算法的基本原理图。client发出请求给某台server（这里的server是leader，通过选举产生），该leader根据请求信息生成一日志项（log entry，除了包含请求信息，还包括日志编号等信息），写入到本地文件，并将该日志转发给其他server（follower），要求follower复制该日志，当超过半数follower复制并返回成功后，该日志将变成为committed（提交）状态，leader就将该日志应用到状态机，最后再返回给client。raft认为，如果每个server的日志顺序一致，每个日志内的内容一致，那么状态机执行日志后的最终状态也一致。\n\n![raft](raft01.png)\n\n注意， leader总是会将client的请求写到日志文件中。无论leader还是follower只有committed的日志项才会被应用到状态机（比如follower可能会收到leader的某个日志项，但该日志项最终没有成为committed状态，这种日志不会被follower应用到状态机），另外leader一旦确认某个日志项成为committed状态后，将在后续的心跳中通知follower该日志已经成为committed。这个过程实质就是轻量的2PC过程。\n\n## leader选举\n\nStep1  初始A/B/C都是follower，每个server都有一个选举定时器，超时后就发起选举\nStep2  A的选举定时器时间先到，变成candidate，首先投票给自己，vote count=1\nStep3  A向B/C发起选举请求，要求投票给自己\nStep4  B/C收到请求后，发现本轮（term）还没有投票过，便同意投票给A，同时B/C的选举定时器被重装\nStep5  A收到的投票数（vote count，包括A自己）超过半数，A成为leader\nStep6  A作为leader开始跟follower进行心跳，B/C收到心跳后会重置选举定时器 \n\n初始化时，每个server默认是follower，每个server都会启动一个选举定时器，如果在超时时间内没有收到leader的心跳或者复制日志请求，该server就认为leader已经死机，将自己角色置为candidate，并向其他server发起选举请求（请求其他server投票给自己，发起者本身会投票给自己），如果有收到超过半数（包括发起者自己）的投票同意，则转换为leader。在超时之前，如果有收到任何其他server的请求（假设某个状态，leader的状态OK，leader会发心跳给每个follower），则重置该定时器（定时器重新从0开始计时）。一般情况下心跳间隔（heartbeat interval）要比选举定时器小很多。\n\n(1) 有没有可能两个server同时发出选举请求？\n有这种可能，但raft要求在一个选举周期内，只能投票给一个server，如果在一个选举周期内收到多个server的投票请求，只会投票给第一个server，后续其他server的都会拒绝。\n\n(2) 什么是一个选举周期？\nraft中用term（一个整形值）表示一个选举周期。 server收到的选举请求参数中带有请求者的term信息， 如果server发现这个term我已经投过票了，那其他server相同term的选举请求就会被拒绝。每个server都保存有term信息，正常情况下，所有server的term是一致的，但可能出现某些server由于故障，比如死机很久后又恢复，其保存的term值可能已经远小于其他server。每个server的term更新逻辑如下，如果server收到的包（投票请求或者复制日志请求或者某请求的返回包）信息中的term比自己当前的term要大，则更新自己的term为包信息信息中的term，如果当前是leader或者candidate，则降级为follower。某台candidate发起选举的时候，将当前自己的term 值加1，作为发起选举请求的term参数，一旦选举确认leader后，之后的日志项中的term信息都是该term值，直到发送下次选举产生新term。Server当前的term会持久化存储，机器重启后会从文件中读取。\n\n(3) follower什么情况下会投票给candidate？\n除了之前说的，相同term的请求，follower只会投票给第一个candidate外，follower还会判断follower自己的term是否小于请求者的term，如果不满足，则投票反对，并将自己的term信息告知请求者，candidate收到后，发现有比自己大的term存在，立即降级为follower。\n\n(4) 如果2个server同时发起请求，其他server可能会投票给不同的server，这样2个发起者都可能收到不超过半数的投票，raft是如何处理的呢？\nraft中将这种情况描述为split vote。系统中有四个节点A/B/C/D，A和C同时发起投票，D投票给A，B投票给C，这样A/C都没有获取超过半数（>2票）的投票，都不能从candidate转换为leader。raft中，A/C将等到下一个选举定时器超时到来后，再重新发起投票（term值会再次增加），A/C发起投票的时间将会被错开（这里通过设置选举超时时间为某个范围内随机数），这样下次再出现split vote的几率几乎为0。\n\n(5) 系统可能同时存在2个leader吗？\n有可能。假设系统有五个节点，A/B/C/D/E，A为leader，某个时刻C/D/E可能由于网络原因跟A/B隔离，这样A/B形成孤岛。C/D/E由于收不到leader A的心跳，在选举定时器超时后，将发起选举请求，假设C发起选举投票，C将收到D/E的同意，无法收到A/B的回应，但仍有超过半数的投票（加上C自己是3票），C将成为leader状态，这样系统中A/C同时作为leader存在。如果用户的请求到达A，A请求C/D/E，C/D/E超时，这样A收不到超过半数的回应，该次请求的日志不会被committed，也不会被应用到A的状态机，但C处理的客户但请求对于日志就会被committed，此时的A实质是伪leader。\n\n(6) leader可能被降级吗?\n会有可能。仍以上面的为例，假设A/B与C/D/E间的网络恢复，由于有2个leader同时存在，A/B可能收到leader C的请求，C/D/E有可能收到leader A的请求。在raft中，如果follower收到的leader/cadidate请求中的term比自己当前的term还小，就会立即返回失败。失败信息包含当前follower的term。A是leader，发现有比自己term还大的，立即降级自己，变为follower。同理，candidate在处理投票时如果发现有比自己大的term，也立即降级，成为follower。\n\n## 日志复制\n\n每个日志项（log entry）包括index，term，command。index是表示日志索引号，由leader生成，单调递增。term代表一个选举周期，单调递增。command表示请求的信息。日志有两种状态，committed（提交），uncommitted（未提交），一旦日志为提交状态，就可以应用到状态机。在raft中，客户端请求都是先到leader，leader生成日志，然后leader再将该日志复制给follower，如果超过半数的follower回复成功，则该日志成为committed状态，可以应用到状态机。\n\n下图中每行表示一个server的日志序列（用S1~S5表示这五个server），S1是当前的leader，记录有8个日志项，term为1的有3个，term为2的为1个，term为3的有4个。S4只有2个日志项，并且term都为1，日志的lastLogIndex为2，lastLogTerm为1。Index为1～7的日志项都在超过半数的server存在，这些日志被称为committed（提交的），而index=8的日志，只在S1和S3存在，不超过半数，所以日志项8不是committed。\n\n![raft](raft02.png)\n\n由于网络的复杂性，可能导致各server的日志不同步。\n\n![raft](raft03.png)\n\na~b表示的是server的日志没有跟leader同步，缺少了部分committed的日志，c~f表示server包含多余的未提交的日志项。以f为例，出现这种情况的场景可能是这样，在term为2时，f被选举为server，并收到客户端3次请求，生成日志，index为4/5/6，term都是2，但日志还没有来得及同步给其他server，f死机，然后又迅速回复，重新发起选举并成为leader，term变为3，这时f又收到客户端5次请求，生成日志，index为7/8/9/10/11，但未来得及同步给其他server，f又死机，并且一直没有恢复。之后，e被选举为新leader，新日志index将会按照e当前的最新index加1来生成。这样就在e内生成了index=4，term=4的日志，与f中的index=4，term=2的日志项含有相同index。这种情况是允许出现的，因为f中的日志index=4是未提交状态，这种日志不能被应用到状态机，实际上，在后续的同步中，将被新leader的日志覆盖。\n\n### 日志复制的过程\n\nRaft的日志复制都是由leader发起\n\nleader请求follower复制时，会带上leader当前的term，最近日志的index和term，及当前leader已经提交日志的日志编号。follower收到请求后，会检查2个条件，第一是term的检查，如果follower的term比leader还要大，则认为leader已经过时（比如之前讨论的出现孤岛现象，系统中有2个leader），返回失败。第2个检查是follower检测其日志中是否有匹配preLogIndex和preLogTerm的项，这里又可能出现两种情况，一是follower中不存在这样的preLogIndex，二是存在这样的preLogIndex，但其中的term和preLogTerm不一样，这两种情况，follower会返回失败，否则follower认为可以复制。\n\nleader请求复制term=3，index=5的日志项，请求时的preLogIndex为4，preLogTerm为2。在上面部分，follower有对应的preLogIndex及preLogTerm的日志项，复制成功，而下面部分，follower的preLogTerm不匹配，因此，follower会返回失败。\n\n![raft](raft05.png)\n\nleader只会append自己的日志，而不会去删除或者覆盖自身的日志，而follower上的日志可能被覆盖。系统中每个follower的日志跟leader的同步进度并不一致，比如死机很久的follower的日志已经远远落后其他follower。这里leader为每个follower保存了nextIndex和matchIndex，nextIndex为leader下一次尝试跟follower同步的index，matchIndex表示follower当前已经跟leader同步的最大index。nextIndex决定了请求时的preLogIndex和preLogTerm，如果发现follower返回失败，会将nextIndex递减，直到找到follower返回成功的index，这种场景一般发生在follower落后leader很多的情况下出现或者follower有一些多余的混杂日志。\n\n![raft](raft06.png)\n\nleader首先用preLogIndex=10，preLogTerm=6和server a进行日志同步，server a发现自己没有这样的匹配日志，会返回失败，然后leader会将nextIndex递减，变成9，这时再跟a同步，请求的preLogIndex=9，preLogTerm=6，a仍然返回失败，leader反复重试，直到发现preLogIndex=4，preLogTerm=4时与a匹配，这时a首先将index=4之后的日志全部擦除，然后将leader中index5~index10直接的日志复制到本机，这样a就与leader同步了。b中follower含有未提交的日志，这些日志在同步过程中，会被清理。","tags":["分布式"]},{"title":"Spring 相关","url":"/2019/03/20/Spring/","content":"** {{ title }}：** <Excerpt in index | 首页摘要>\n总结的一些Spring\n<!-- more -->\n<The rest of contents | 余下全文>\n# Spring Bean 的生命周期\n\n- 实例化bean对象(通过构造方法或者工厂方法)\n- 设置对象属性(setter等)（依赖注入）\n- 如果Bean实现了BeanNameAware接口，工厂调用Bean的setBeanName()方法传递Bean的ID。（和下面的一条均属于检查Aware接口）\n- 如果Bean实现了BeanFactoryAware接口，工厂调用setBeanFactory()方法传入工厂自身\n- 将Bean实例传递给Bean的前置处理器的postProcessBeforeInitialization(Object bean, String beanname)方法\n  调用Bean的初始化方法\n- 将Bean实例传递给Bean的后置处理器的postProcessAfterInitialization(Object bean, String beanname)方法\n- 使用Bean\n- 容器关闭之前，调用Bean的销毁方法\n\n# Bean的作用域\n\nSpring 3中为Bean定义了5中作用域，分别为singleton（单例）、prototype（原型）、request、session和global session，5种作用域说明如下：\n\n1. singleton：单例模式，Spring IoC容器中只会存在一个共享的Bean实例，无论有多少个Bean引用它，始终指向同一对象。Singleton作用域是Spring中的缺省作用域，也可以显示的将Bean定义为singleton模式，配置为：\n   - <bean id=\"userDao\" class=\"com.ioc.UserDaoImpl\" scope=\"singleton\"/>\n2. prototype:原型模式，每次通过Spring容器获取prototype定义的bean时，容器都将创建一个新的Bean实例，每个Bean实例都有自己的属性和状态，而singleton全局只有一个对象。根据经验，对有状态的bean使用prototype作用域，而对无状态的bean使用singleton作用域。\n3. request：在一次Http请求中，容器会返回该Bean的同一实例。而对不同的Http请求则会产生新的Bean，而且该bean仅在当前Http Request内有效。\n   - <bean id=\"loginAction\" class=\"com.cnblogs.Login\" scope=\"request\"/>,针对每一次Http请求，Spring容器根据该bean的定义创建一个全新的实例，且该实例仅在当前Http请求内有效，而其它请求无法看到当前请求中状态的变化，当当前Http请求结束，该bean实例也将会被销毁。\n4. session：在一次Http Session中，容器会返回该Bean的同一实例。而对不同的Session请求则会创建新的实例，该bean实例仅在当前Session内有效。\n   - <bean id=\"userPreference\" class=\"com.ioc.UserPreference\" scope=\"session\"/>,同Http请求相同，每一次session请求创建新的实例，而不同的实例之间不共享属性，且实例仅在自己的session请求内有效，请求结束，则实例将被销毁。\n5. global Session：在一个全局的Http Session中，容器会返回该Bean的同一个实例，仅在使用portlet context时有效。\n\n# Bean自动装配的区别\n\n在Spring框架中共有5种自动装配。\n\n1. no：这是Spring框架的默认设置，在该设置下自动装配是关闭的，开发者需要自行在bean定义中用标签明确的设置依赖关系。\n2. byName：该选项可以根据bean名称设置依赖关系。当向一个bean中自动装配一个属性时，容器将根据bean的名称自动在在配置文件中查询一个匹配的bean。如果找到的话，就装配这个属性，如果没找到的话就报错。\n3. byType：该选项可以根据bean类型设置依赖关系。当向一个bean中自动装配一个属性时，容器将根据bean的类型自动在在配置文件中查询一个匹配的bean。如果找到的话，就装配这个属性，如果没找到的话就报错。\n4. constructor：造器的自动装配和byType模式类似，但是仅仅适用于与有构造器相同参数的bean，如果在容器中没有找到与构造器参数类型一致的bean，那么将会抛出异常。\n5. autodetect：该模式自动探测使用构造器自动装配或者byType自动装配。首先，首先会尝试找合适的带参数的构造器，如果找到的话就是用构造器自动装配，如果在bean内部没有找到相应的构造器或者是无参构造器，容器就会自动选择byTpe的自动装配方式。\n\n# spring（数据库）事务隔离级别分为四种（级别递减）：\n\n1、Serializable （串行化）：最严格的级别，事务串行执行，资源消耗最大；\n\n2、REPEATABLE READ（重复读） ：保证了一个事务不会修改已经由另一个事务读取但未提交（回滚）的数据。避免了“脏读取”和“不可重复读取”的情况，但不能避免“幻读”，但是带来了更多的性能损失。\n\n3、READ COMMITTED （提交读）：大多数主流数据库的默认事务等级，保证了一个事务不会读到另一个并行事务已修改但未提交的数据，避免了“脏读取”，但不能避免“幻读”和“不可重复读取”。该级别适用于大多数系统。\n\n4、Read Uncommitted（未提交读） ：事务中的修改，即使没有提交，其他事务也可以看得到，会导致“脏读”、“幻读”和“不可重复读取”。\n\n脏读、不可重复读、幻读：\n\n也许有很多读者会对上述隔离级别中提及到的 脏读、不可重复读、幻读 的理解有点吃力，我在这里尝试使用通俗的方式来解释这三种语义：\n\n脏读：所谓的脏读，其实就是读到了别的事务回滚前的脏数据。比如事务B执行过程中修改了数据X，在未提交前，事务A读取了X，而事务B却回滚了，这样事务A就形成了脏读。\n\n也就是说，当前事务读到的数据是别的事务想要修改成为的但是没有修改成功的数据。\n\n不可重复读：事务A首先读取了一条数据，然后执行逻辑的时候，事务B将这条数据改变了，然后事务A再次读取的时候，发现数据不匹配了，就是所谓的不可重复读了。\n\n也就是说，当前事务先进行了一次数据读取，然后再次读取到的数据是别的事务修改成功的数据，导致两次读取到的数据不匹配，也就照应了不可重复读的语义。\n\n幻读：事务A首先根据条件索引得到N条数据，然后事务B改变了这N条数据之外的M条或者增添了M条符合事务A搜索条件的数据，导致事务A再次搜索发现有N+M条数据了，就产生了幻读。\n\n也就是说，当前事务读第一次取到的数据比后来读取到数据条目少。\n\n不可重复读和幻读比较：\n\n两者有些相似，但是前者针对的是update或delete，后者针对的insert。\n\n# Spring事务传播\n\nSpring事务的传播行为定义了外层方法[注1]调用带有@Transactional的当前方法时，事务如何进行传播的规则，共有7种类型： \n（1）PROPAGATION.REQUIRED(默认) \n如果外层方法有事务，则当前方法加入外层事务；如果外层方法没有事务，则当前方法新建一个事务。 \n（2）PROPAGATION.REQUIRES_NEW \n当前方法总是开启一个新的事务，如果外层方法有事务，则将外层事务挂起，先执行当前方法的事务（外层事务和当前方法的事务是两个不同的事务）。 \n当当前方法发生回滚并抛出RuntimeException时，如果该异常被捕获，则外层方法的事务不会因此回滚；如果该异常没有被捕获，则外层方法的事务就会因此而回滚。 \n当外层方法发生回滚时，如果其回滚发生在当前方法前，则当前方法得不到执行；如果其回滚发生在当前方法之后，则当前方法不会因此而回滚。 \n（3）PROPAGATION.NESTED \n如果外层方法没事务，则当前方法新建一个事务；如果外层方法有事务，则把当前方法当成外层事务的一部分（使用savepoint实现），外层方法事务的rolback或者commit都会影响当前方法[注2]，而当前方法的rolback不会导致外层事务回滚，除非rollback过程抛出了RuntimeException且该异常没有被捕获。 \n（4）PROPAGATION.SUPPORTS \n如果外层方法没事务，那当前方法就按普通方法执行；如果外层方法有事务，则使用外层方法的事务。 \n（5）PROPAGATION.NOT_SUPPORTED \n当前方法总是非事务地执行，如果外层方法有事务则把事务挂起，当前方法还是以普通方法执行。 \n（6）PROPAGATION.NEVER \n如果外层方法没事务，那当前方法就按普通方法执行；如果外层方法有事务，则当前方法抛出异常。 \n（7）PROPAGATION.MANDATORY 如果外层方法没事务，则当前方法就会抛出异常；如果外层方法有事务，则当前方法使用外层事务。\n\n# DispatherServlet\n\n在整个SpringMVC框架中，DispatherServlet吃于核心位置，它负责协调和组织不同组建完成请求处理并返回响应工作。\n\nSpringMVC的请求处理大致流程：\n\n1. Tomcat 启动，对 DispatcherServlet 进行实例化，然后调用它的 init() 方法进行初始化，在这个初始化过程中完成了\n2. 对 web.xml 中初始化参数的加载；建立 WebApplicationContext (SpringMVC的IOC容器)；进行组件的初始化\n3. 客户端发出请求，由 Tomcat 接收到这个请求，如果匹配 DispatcherServlet 在 web.xml 中配置的映射路径，Tomcat 就将请求转交给 DispatcherServlet 处理\n4. DispatcherServlet 从容器中取出所有 HandlerMapping 实例（每个实例对应一个 HandlerMapping 接口的实现类）并遍历，每个 HandlerMapping 会根据请求信息，通过自己实现类中的方式去找到处理该请求的 Handler (执行程序，如Controller中的方法)，并且将这个 Handler 与一堆 HandlerInterceptor (拦截器) 封装成一个 HandlerExecutionChain 对象，一旦有一个 HandlerMapping 可以找到 Handler 则退出循环\n5. DispatcherServlet 取出 HandlerAdapter 组件，根据已经找到的 Handler，再从所有 HandlerAdapter 中找到可以处理该 Handler 的 HandlerAdapter 对象\n6. 执行 HandlerExecutionChain 中所有拦截器的 preHandler() 方法，然后再利用 HandlerAdapter 执行 Handler ，执行完成得到 ModelAndView，再依次调用拦截器的 postHandler() 方法\n7. 利用 ViewResolver 将 ModelAndView 或是 Exception（可解析成 ModelAndView）解析成 View，然后 View 会调用 render() 方法再根据 ModelAndView 中的数据渲染出页面\n8. 最后再依次调用拦截器的 afterCompletion() 方法，这一次请求就结束了\n\nDispacherServlet源码分析：\n\nDispatcherServlet 继承自 HttpServlet，它遵循 Servlet 里的“init-service-destroy”三个阶段。\n\n1、初始化\n\nDispatcherServlet 的 init() 方法在其父类 **HttpServletBean** 中实现的，它覆盖了 GenericServlet 的 init() 方法，主要作用是加载 web.xml 中 DispatcherServlet 的 <init-param> 配置，并调用子类的初始化。\n\n在 HttpServletBean 的 init() 方法中调用了 initServletBean() 这个方法，它是在 **FrameworkServlet** 类中实现的，主要作用是建立 WebApplicationContext 容器（有时也称上下文），并加载 SpringMVC 配置文件中定义的 Bean 到改容器中，最后将该容器添加到 ServletContext 中。\n\nWebApplicationContext 继承于 ApplicationContext 接口，从容器中可以获取当前应用程序环境信息，它也是 SpringMVC 的 IOC 容器。\n\n建立好 WebApplicationContext(上下文) 后，通过 onRefresh(ApplicationContext context) 方法回调，进入 DispatcherServlet 类中。onRefresh() 方法，提供 SpringMVC 的初始化。\n\n```java\n@Override\n    protected void onRefresh(ApplicationContext context) {\n        initStrategies(context);\n    }\n    protected void initStrategies(ApplicationContext context) {\n        initMultipartResolver(context);\n        initLocaleResolver(context);\n        initThemeResolver(context);\n        initHandlerMappings(context);\n        initHandlerAdapters(context);\n        initHandlerExceptionResolvers(context);\n        initRequestToViewNameTranslator(context);\n        initViewResolvers(context);\n        initFlashMapManager(context);\n    }\n```\n\n\n\ninitHandlerMappings() 方法从 SpringMVC 的容器及 Spring 的容器中查找所有的 HandlerMapping 实例，并把它们放入到 handlerMappings 这个 list 中。这个方法并不是对 HandlerMapping 实例的创建，HandlerMapping 实例是在上面 WebApplicationContext 容器初始化，即 SpringMVC 容器初始化的时候创建的。\n\n```java\nprivate void initHandlerMappings(ApplicationContext context) {\n    this.handlerMappings = null;\n    if (this.detectAllHandlerMappings) {\n        // 从 SpringMVC 的 IOC 容器及 Spring 的 IOC 容器中查找 HandlerMapping 实例\n        Map<String, HandlerMapping> matchingBeans =\n        　　　　BeanFactoryUtils.beansOfTypeIncludingAncestors(context, HandlerMapping.class, true, false);\n        if (!matchingBeans.isEmpty()) {\n            this.handlerMappings = new ArrayList<HandlerMapping>(matchingBeans.values());\n            // 按一定顺序放置 HandlerMapping 对象\n            OrderComparator.sort(this.handlerMappings);\n        }\n    } else {\n        try {\n            HandlerMapping hm = context.getBean(HANDLER_MAPPING_BEAN_NAME, HandlerMapping.class);\n            this.handlerMappings = Collections.singletonList(hm);\n        } catch (NoSuchBeanDefinitionException ex) {\n            // Ignore, we'll add a default HandlerMapping later.\n        }\n    }\n    // 如果没有 HandlerMapping，则加载默认的\n    if (this.handlerMappings == null) {\n        this.handlerMappings = getDefaultStrategies(context, HandlerMapping.class);\n    }\n}\n```\n\nInitHandlerAdapters方法同理\n\n2、处理请求：\n\nHttpServlet 提供了 doGet()、doPost() 等方法，DispatcherServlet 中这些方法是在其父类 FrameworkServlet 中实现的，这些方法有调用了processRequest()方法，再调用doService()方法。DispatcherServlet 的 doService() 方法主要是设置一些 request 属性，并调用 doDispatch() 方法进行请求分发处理，doDispatch() 方法的主要过程是通过 HandlerMapping 获取 Handler，再找到用于执行它的 HandlerAdapter，执行 Handler 后得到 ModelAndView ，ModelAndView 是连接“业务逻辑层”与“视图展示层”的桥梁，接下来就要通过 ModelAndView 获得 View，再通过它的 Model 对 View 进行渲染。\n\n# springmvc 处理流程\n\n1、  首先用户 发送请求—— >DispatcherServlet ， 分发器收到请求后自己不进行处理，而是委托给其他的解析器进行处理，作为统一访问点，进行全局的流程控制；\n\n2、  DispatcherServlet —— >HandlerMapping ， HandlerMapping 将会把请求映射为 HandlerExecutionChain 对象（包含一个 Handler 处理器（Controller）对象、多个 HandlerInterceptor 拦截器）对象，通过这种策略模式，很容易添加新的映射策略；\n\n3、  DispatcherServlet —— >HandlerAdapter ， HandlerAdapter 将会把处理器包装为适配器，从而支持多种类型的处理器，即适配器设计模式的应用，从而很容易支持很多类型的处理器；\n\n4、  HandlerAdapter —— > 处理器功能处理方法的调用， HandlerAdapter 将会根据适配的结果调用真正的处理器的功能处理方法，完成功能处理（在调用处理器前会先执行spring的前置拦截器preHandle）；并返回一个 ModelAndView 对象（包含模型数据、逻辑视图名），返回视图后会执行spring的后置拦截器postHandle；\n\n5、  ModelAndView 的逻辑视图名—— > ViewResolver ， ViewResolver 将把逻辑视图名解析为具体的 View，通过这种策略模式，很容易更换其他视图技术；\n\n6、  View —— > 渲染 ，View 会根据传进来的 Model 模型数据进行渲染，此处的 Model 实际是一个 Map 数据结构，因此很容易支持其他视图技术（这步处理完后执行spring的完成后拦截器）；\n\n7、  返回控制权给 DispatcherServlet ， 由 DispatcherServlet 返回响应给用户，到此一个流程结束。\n\n# IOC\n\n如果一个类A的功能实现需要借助于B，那么就成类B是类A的依赖，如果在类A的内部去实例化类B，那么两者之间会出现高耦合。一旦类B出现了问题，类A也需要进行改造，如果这样的情况较多，每个类之间有很多的依赖，那么就会出现牵一发而动全身的情况，程序会极难维护，并且很容易出现问题。要解决这个问题，就要把A类对B类的控制权抽离出来，交给第三方去做，把控制权反转给第三方，就称作控制反转（IOC）。控制反转是一种思想，是能够解决问题的一种可能的结果。而依赖注入是实现方式。由第三方通过构造函数、属性注入等方法，注入到A类，这样就极大程度的对类A和类B进行了解耦。\n\n- `BeanFactory`。基础类型`IoC容器`，提供完整的`IoC`服务支持。如果没有特殊指定，默认采用延迟初始化策略（`lazy-load`）。只有当客户端对象需要访问容器中的某个受管对象的时候，才对该受管对象进行初始化以及依赖注入操作。所以，相对来说，容器启动初期速度较快，所需要的资源有限。对于资源有限，并且功能要求不是很严格的场景，`BeanFactory`是比较合适的`IoC容器`选择。\n- `ApplicationContext`。`ApplicationContext`在`BeanFactory`的基础上构建，是相对比较高级的容器实现，除了拥有`BeanFactory`的所有支持，`ApplicationContext`还提供了其他高级特性，比如事件发布、国际化信息支持等，`ApplicationContext`所管理的对象，在该类型容器启动之后，默认全部初始化并绑定完成。所以，相对于`BeanFactory`来说，`ApplicationContext`要求更多的系统资源，同时，因为在启动时就完成所有初始化，容\n  器启动时间较之`BeanFactory`也会长一些。在那些系统资源充足，并且要求更多功能的场景中，`ApplicationContext`类型的容器是比较合适的选择。\n\n但是我们无论使用哪个容器，我们都需要通过某种方法告诉容器关于对象依赖的信息。\n\n在`BeanFactory`容器中，每一个注入对象都对应一个`BeanDefinition`实例对象，该实例对象负责保存注入对象的所有必要信息，包括其对应的对象的class类型、是否是抽象类、构造方法参数以及其他属性等。当客户端向`BeanFactory`请求相应对象的时候，`BeanFactory`会通过这些信息为客户端返回一个完备可用的对象实例。\n\n那么`BeanDefinition`实例对象的信息是从哪而来呢？这里就要引出一个专门加载解析配置文件的类了，他就是`BeanDefinitionReader`，对应到`xml`配置文件，就是他的子类`XmlBeanDefinitionReader`，`XmlBeanDefinitionReader`负责读取`Spring`指定格式的`XML`配置文件并解析，之后将解析后的文件内容映射到相应的`BeanDefinition`。\n\n我们把容器创造一个对象的过程称为`Bean的注册`，实现`Bean的注册`的接口为`BeanDefinitionRegistry`，其实`BeanFactory`只是一个接口，他定义了如何获取容器内对象的方法，我们所说的`BeanFactory`容器，其实是这个接口的是实现类，但是具体的`BeanFactory`实现类同时也会实现`BeanDefinitionRegistry`接口，这样我们才能通过容器注册对象和获取对象。我们通过`BeanDefinitionRegistry`的`rsgisterBeanDefinition(BeanDefinition beandefinition)`方法来进行`Bean的注册`。\n\n我们来总结一下一个Bean是如何注册到容器中，然后被我们获取的： 首先我们需要配置该Bean的依赖信息，通常我们配置在xml文件中，然后我们通过XmlBeanDefinitionReader读取文件内容，然后将文件内容映射到相应的BeanDefinition，然后我们可以通过BeanFactory和BeanDefinitionRegistry的具体实现类,比如DefaultListableBeanFactory实现Bean的注册和获取\n\nSpring`提供了一种叫做`BeanFactoryPostProcessor`的容器扩展机制。该机制允许我们在容器实例化相应对象之前，对注册到容器的`BeanDefinition`所保存的信息做相应的修改。\n\n首先是`BeanFactory`，我们也知道`BeanFactory`是`ApplicationContext`的父类，那么功能上`BeanFactory`也是比较弱小的，我们需要使用手动写代码来应用`BeanFactoryPostProcessor`\n\n接着是更高级的`ApplicationContext`容器，这个就牛逼多了，他可以自动识别容器中的`BeanFactoryPostProcessor`实例对象，并使用他们，是的，是“他们”，我们可以在一个容器中使用多个`BeanFactoryPostProcessor`\n\n# AOP\n\n- Aspect（切面）： Aspect 声明类似于 Java 中的类声明，在 Aspect 中会包含着一些 Pointcut 以及相应的 Advice。\n  Joint point（连接点）：表示在程序中明确定义的点，典型的包括方法调用，对类成员的访问以及异常处理程序块的执行等等，它自身还可以嵌套其它 joint point。\n- Pointcut（切点）：表示一组 joint point，这些 joint point 或是通过逻辑关系组合起来，或是通过通配、正则表达式等方式集中起来，它定义了相应的 Advice 将要发生的地方。\n- Advice（增强）：Advice 定义了在 Pointcut 里面定义的程序点具体要做的操作，它通过 before、after 和 around 来区别是在每个 joint point 之前、之后还是代替执行的代码。\n- Target（目标对象）：织入 Advice 的目标对象.。\n- Weaving（织入）：将 Aspect 和其他对象连接起来, 并创建 Adviced object 的过程\n\nAOP中的Joinpoint可以有多种类型：构造方法调用，字段的设置和获取，方法的调用，方法的执行，异常的处理执行，类的初始化。也就是说在AOP的概念中我们可以在上面的这些Joinpoint上织入我们自定义的Advice，但是在Spring中却没有实现上面所有的joinpoint，确切的说，Spring只支持方法执行类型的Joinpoint。\n\nAdvice 的类型\n\nbefore advice, 在 join point 前被执行的 advice. 虽然 before advice 是在 join point 前被执行, 但是它并不能够阻止 join point 的执行, 除非发生了异常(即我们在 before advice 代码中, 不能人为地决定是否继续执行 join point 中的代码)\n\n- after return advice, 在一个 join point 正常返回后执行的 advice\n- after throwing advice, 当一个 join point 抛出异常后执行的 advice\n- after(final) advice, 无论一个 join point 是正常退出还是发生了异常, 都会被执行的 advice.\n- around advice, 在 join point 前和 joint point 退出后都执行的 advice. 这个是最常用的 advice.\n- introduction，introduction可以为原有的对象增加新的属性和方法。\n\n在Spring中，通过动态代理和动态字节码技术实现了AOP，这些内容，我们将在以后进行讲解。\n\n**AOP 名词的大白话解说**\n\n　　1、**通知**　　--  Advice\n\n　　**就是要给目标类织入的事情**。就是我们说的额外的一些共同的事情，也就是上面说的 事务，日志等。你给先定义好，然后在想用的地方用一下。\n\n　　2、**连接点**　　-- JoinPoint\n\n 　　就是 spring 允许你使用通知的地方，那可真就多了，基本每个方法的前，后（两者都有也行），或抛出异常时都可以是连接点，spring 的话只支持方法连接点。和方法有关的前前后后（抛出异常），都是连接点。**一个类的所有方法前、后、抛出异常时等都是连接点。**\n\n　　3、**切入点**　　-- Pointcut\n\n　　上面说的连接点的基础上，来定义切入点，你的一个类里，有15个方法，那就有几十个连接点了对把，但是你并不想在所有方法附近都使用通知（使用叫织入，下面再说），你只想让其中的几个，在调用这几个方法之前，之后或者抛出异常时干点什么，那么就用切点来定义这几个方法，让切点来筛选连接点，选中那几个你想要的方法。（比如需要开启事务的只是“ save * ”、“ update * ”..等等这些方法）。**切入点就是定义了哪个类里面的哪些方法的会得到通知**。\n\n　　4、**切面**　　-- Aspect\n\n　　**切面是通知和切入点的结合**。现在发现了吧，没连接点什么事情，连接点就是为了让你好理解切点，搞出来的，明白这个概念就行了。**通知说明了干什么**和什么时候干（什么时候通过方法名中的before,after，around等就能知道），而**切入点说明了在哪干**（指定到底是哪个方法），这就是一个完整的切面定义。\n\n　　5、**织入**　　-- weaving\n\n　　**把切面应用到目标对象来创建新的代理对象的过程。**可以在编译时、类加载时、运行时完成的织入，spring 采用的是 **在运行时完成织入**。\n\n　　6、**引入**　　-- introduction\n\n　　允许我们向现有的类添加新方法属性。这不就是把切面（也就是新方法属性：通知定义的）用到目标类中吗~\n\n　　7、**目标**　　-- target\n\n　　引入中所提到的目标类，也就是**要被通知的对象**，**也就是真正的业务逻辑**，他可以在毫不知情的情况下，被咱们织入切面。而自己专注于业务本身的逻辑。\n\n　　8、**AOP 的代理**　　-- AOP Proxy\n\n　　**目标对象被织入增强后产生的结果类。**我的理解它是 spring 为了骗过 jvm 的类型检查，搞出来的一个伪装类。\n\n　　spring 伪装采用了两种方式：\n\n　　① 实现和目标类相同的接口　　-- 与目标类为双胞胎兄弟（要找我哥办事，弟弟我冒充哥哥收点礼物，再让我哥给你办事~）\n\n　　② 生成子类调用　　-- 给目标类当儿子（学会了爸爸的本事，都找我办就好了，但是我要先收点礼物~）\n\n在Spring的AOP编程中:如果加入容器的目标对象有实现接口,用JDK代理;如果目标对象没有实现接口,用Cglib代理\n\n# Java的代理模式\n\n### 静态代理\n\n静态代理在使用时,需要定义接口或者父类,被代理对象与代理对象一起实现相同的接口或者是继承相同父类.\n\n### 动态代理\n\n- 代理对象的生成,是利用JDK的API,动态的在内存中构建代理对象(需要我们指定创建代理对象/目标对象实现的接口的类型)\n\n```java\nstatic Object newProxyInstance(ClassLoader loader, Class<?>[] interfaces,InvocationHandler h )\n```\n\n参数含义：\n\n- `ClassLoader loader,`:指定当前目标对象使用类加载器,获取加载器的方法是固定的\n- `Class<?>[] interfaces,`:目标对象实现的接口的类型,使用泛型方式确认类型\n- `InvocationHandler h`:事件处理,执行目标对象的方法时,会触发事件处理器的方法,会把当前执行目标对象的方法作为参数传入\n\n### Cglib代理\n\n上面的静态代理和动态代理模式都是要求目标对象是实现一个接口的目标对象,但是有时候目标对象只是一个单独的对象,并没有实现任何的接口,这个时候就可以使用以目标对象子类的方式类实现代理,这种方法就叫做:Cglib代理\n\nCglib代理,也叫作子类代理,它是在内存中构建一个子类对象从而实现对目标对象功能的扩展.\n\n- JDK的动态代理有一个限制,就是使用动态代理的对象必须实现一个或多个接口,如果想代理没有实现接口的类,就可以使用Cglib实现.\n- Cglib是一个强大的高性能的代码生成包,它可以在运行期扩展java类与实现java接口.它广泛的被许多AOP的框架使用,例如Spring AOP和synaop,为他们提供方法的interception(拦截)\n- Cglib包的底层是通过使用一个小而块的字节码处理框架ASM来转换字节码并生成新的类.不鼓励直接使用ASM,因为它要求你必须对JVM内部结构包括class文件的格式和指令集都很熟悉.\n\nCglib子类代理实现方法:\n\n- 需要引入cglib的jar文件,但是Spring的核心包中已经包括了Cglib功能,所以直接引入`pring-core-3.2.5.jar`即可.\n- 引入功能包后,就可以在内存中动态构建子类\n- 代理的类不能为final,否则报错\n- 目标对象的方法如果为final/static,那么就不会被拦截,即不会执行目标对象额外的业务方法.\n\n# Spring 循环引用\n\n当Spring容器在创建A时，会发现其引用了B，从而会先去创建B。同样的，创建B时，会先去创建C，而创建C时，又先去创建A。最后A、B、C之间互相等待，谁都没法创建成功。\n\n要想打破这个环，那么这个环中至少需要有一个bean可以在自身的依赖还没有得到满足前，就能够被创建出来（最起码要被实例化出来，可以先不注入其需要的依赖）。这种bean只能是通过属性注入依赖的类，因为它们可以先使用默认构造器创建出实例，然后再通过setter方法注入依赖。而通过构造器注入依赖的类，在它的依赖没有被满足前，无法被实例化。而且这个bean，还必须是singleton，不能是prototype。\n\nSpring容器启动后，如果我们去获取singletonA，那么容器的操作步骤大致如下：\n\n- 尝试创建bean singletonA，发现singletonA是singleton，且不是通过构造器注入依赖，那么先使用默认构造器创建一个A的实例，并保存对它的引用，并且将singletonA标记为“正在创建中的singleton”。然后发现singletonA依赖了singletonB，所以尝试创建singletonB。\n- 尝试创建bean singletonB，发现singletonB是singleton，且不是通过构造器注入依赖，那么先使用默认构造器创建一个B的实例，并保存对它的引用，并且将singletonB标记为“正在创建中的singleton”。然后发现singletonB依赖了singletonA，所以尝试创建singletonA。\n- 尝试创建singletonA，注意，这时Spring容器发现singletonA“正在创建中”，那么就不会再去创建singletonA，而是返回容器之前保存了的对singletonA的引用。\n- 容器将singletonA通过setter方法注入到singletonB，从而singletonB完成创建。\n- 容器将singletonB通过setter方法注入到singletonA，从而singletonA完成创建。\n\n上述步骤，最重要的是第1步和第3步。在第1步中，容器会保存对singletonA的引用，在第3步中，再返回对singletonA的引用，从而可以成功创建那些依赖了singletonA的bean（本例中是singletonB）。这样，循环依赖的环就在singletonA这个点这里被打破。\n\n**那为什么prototype不能成为打破这个环的一个点呢？原因就在于Spring容器只会对singleton保存引用，而对于prototype，并不会对其保存引用，这就导致在第3步中并不能获得之前创建的bean（因为引用不到它）。**\n\n至于为什么容器不对prototype保存引用，那就涉及到singleton和portotpye的概念，如果也对prototype保存引用，那么其实它就变成了singleton。可以看一下Spring作用域。\n\n按道理，在循环依赖的环里，只要有一个bean，是通过属性注入依赖，并且是singleton，那么这个环就可以被打破，无论获取他们的顺序是怎样。但是我们在第五节得出过结论“只有当获取的第一个bean是通过属性注入依赖的singleton时，才会成功”，为什么会这样呢？这就和Spring的实现有关了，当Spring容器遍历那些循环依赖的bean时，只要遍历到那种已经遍历过一次的bean，并且它们不是通过属性注入依赖的singleton时，就会直接抛出BeanCurrentlyInCreationException异常。\n\n","tags":["Spring"]}]