[{"title":"JAVA JUC","url":"/2019/03/20/20190324/","content":"** {{ title }}：** <Excerpt in index | 首页摘要>\nimport java.util.concurrent ！看 java 高并发程序设计 做了一点总结\n<!-- more -->\n<The rest of contents | 余下全文>\n# import java.util.concurrent ！\n\n- 多种多线程控制方法\n- 线程池\n- JDK并发容器\n\n\n\n\n\n## 多线程控制方法\n\n### 重入锁（synchronized功能扩展）\n\n重入锁可以完全替代synchronized关键字，性能差距不大\n\n重入锁使用ReentrantLock类实现，与synchronize关键字相比，重入锁有显式的加锁释放锁，对逻辑控制更为灵活。\n\n此外还有一些高级功能。\n\n- 中断响应。对于synchronized来说，如果一个线程在等待锁，那么结果只有两种情况，要么它获得这把锁继续执行，要么它就保持等待。而使用重入锁，则提供另外一种可能，那就是线程可以中断，也就是在等待锁的过程中，程序可以根据需要取消对锁的请求。reentrantLock.lockInterruptibly();这个方法是一个可以对中断进行响应的锁申请动作。\n- 锁申请等待限时，给定一个时间，让线程自动放弃获取锁。我们可以使用trylock()方法进行一次限时的等待。\n- 公平锁。公平锁会按照时间的先后顺序，保证先到者先得。公平锁不会产生饥饿。实现公平锁要求系统维护一个有序队列，因此公平锁的实现成本比较高，性能相对低下。\n\n### 重入锁的搭档 condition条件\n\nwait()和notify()条件是和synchronized关键字合作使用的。\n\n而condition条件是与重入锁相关联的。\n\n和object.wait和object.notify方法一样，当线程使用condition.await()方法时，要求线程有相关的重入锁，在condition。await方法调用后，这个线程就会释放这把锁。同理，在condition.signal方法调用时，也要求线程获得相关的锁。\n\n### 允许多个线程同时访问 信号量\n\n广义上说，信号量是对锁的扩展。无论是内部锁synchronize还是重入锁reentrantlock，一次都只允许一个线程访问一个资源。而信号量却可以指定多个线程，同时访问某一个资源。\n\n```java\nfinal Semaphore semp = new Semaphore(5)\n```\n\n申明了一个包含5个许可的信号量，这就意味着同时可以有5个线程进入semp.acquire()～semp.release()之间的代码段。\n\n### ReadWriteLock 读写锁\n\n读写锁允许多个线程同时读，但写写操作和读写操作依然是需要相互等待和持有锁的。如果读操作远远大于写操作，那么读写锁可以发挥最大的功效。\n\n### CountDownLatch 倒计时器\n\n倒计时器是一个非常实用的多线程控制工具类。这个工具常用来控制线程等待，它可以让某一个线程等待直到倒计时结束，在开始执行。\n\n```java\nstatic final CountDownLatch end = new CountDownLatch(10)\n```\n\n生成了一个CountDownLatch的实例，计数数量为10，这代表着需要10个线程完成任务，等待在CountDownLatch上的线程才能继续执行。\n\n```java\nCountDownLatch.countdown()\n```\n\n在线程内调用上面的方法，通知CountDownLatch，一个线程已经完成了任务，倒计时器可以减1.\n\n```java\nCountDownLatch.await()\n```\n\n调用该方法的线程需要等待所有10个线程任务全部完成，待10个任务全部完成后，该线程才能继续执行。\n\n### CyclicBarrier 循环栅栏\n\nCyclicBarrier是另外一种多线程并发控制使用工具。和CountDownLatch非常相似，它可以实现线程间的计数等待，但它的功能比CountDownLatch更加复杂且强大。\n\n在CyclicBarrier中，我们将计数器设为10，那么凑齐第一批10个线程后，计数器归零，然后接着凑齐下一批10个线程。\n\n比CountDownLatch略微强大点，CyclicBarrier可以接受一参数为barrierAction，就是当计数器完成一次计数后，系统会执行的动作。\n\n```java\nCyclicBarrier.awiat()\n```\n\n每个线程调用该方法，表示等待N个线程，当一批线程完成后，才会继续执行下面的任务。\n\nCyclicBarrier可能会有两个异常，InterruptedException和BrokenBarrierException。\n\n### 线程阻塞工具类 LockSupport\n\nLockSupport可以在线程内任意位置让线程阻塞。\n\n- 和Thread.suspend()相比，它弥补了由于resume()发生在suspend()之前，导致线程无法继续执行，并可能产生死锁的情况。\n- 和object.wait()相比，它不需要先获得某个对象的锁，也不会抛出InterruptedException异常。\n\nLockSupport的静态方法park()可以阻塞当前线程，类似的还有parkNanos()、partUntil()等，他们实现了限时的等待。\n\nLockSupport使用了类似于（二元）信号量的机制。它为每个线程准备了一个许可，默认为0。如果许可可用，那么park函数会立即返回，并且消费这个许可（也就是继续执行）；如果不可用，那么会挂起。而unpark会使得一个许可变为可用。\n\n处于park挂起的线程不会像suspend那样还给出一个令人费解的Runnable状态。它会非常明确的给出waiting（parking）。\n\n\n\n\n\n## 线程复用 线程池\n\n为了避免频繁地创建和销毁线程，我们可以创建线程池对线程进行复用。\n\n线程池中，总有那么几个活跃的线程，当你需要使用线程时，从池子中随便拿一个空闲线程，当完成工作后，并不急着关闭线程，而是将这个线程放回池子，方便其他人使用。使用线程池后，创建线程变成了从池子里获得空闲线程，销毁线程变成了向池子归还线程。\n\nJDK Executor框架提供了各种类型的线程池，主要有以下工厂方法。\n\n```java\npublic static ExectorService newFixedThreadPool(int nThreads)\npublic static ExectorService newSingleThreadExecutor()\npublic static ExectorService newCachedThreadPool()\npublic static ScheduleExecutorService newSingleThreadScheduledExecutor()\npublic static ScheduleExecutorService newScheduleThreadPool(int corePoolSize)\n```\n\n以上方法分别返回具有不同特性的线程池。\n\n- newFixedThreadPool(int nThreads) 该方法返回一个固定线程数量的线程池。当有一个新任务提交时，线程中若有空闲线程，则立即执行；若没有，则新的任务会被暂存到一个任务队列，待线程空闲时，便处理在任务队列里的任务。\n- newSingleThreadExecutor() 该方法返回一个只有一个线程的线程池。若多余一个任务被提交到该线程池，任务会被保存到一个任务队列中，待线程空闲，按FIFO的顺序执行队列中的任务。\n- newCachedThreadPool() 该方法返回一个可以根据实际情况调整线程数量的线程池。线程池中的线程数量不确定，但若有空闲线程可以复用，则会优先使用可以复用的线程。若所有的线程都在工作，又有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行复用。\n- newSingleThreadScheduledExecutor() 该方法返回一个ScheduleExecutorService对象，线程池大小为1。ScheduleExecutorService接口在ExecutorService接口之上扩展了在给定时间执行某任务的功能。如在某个固定的延时之后执行，或在周期性执行某个任务。\n- newScheduleThreadPool(int corePoolSize) 该方法返回一个ScheduleExecutorService对象，但该线程池可以指定线程数量。\n\n### 核心线程池的内部实现\n\n```java\n    public ThreadPoolExecutor(int corePoolSize,\n                              int maximumPoolSize,\n                              long keepAliveTime,\n                              TimeUnit unit,\n                              BlockingQueue<Runnable> workQueue,\n                              ThreadFactory threadFactory,\n                              RejectedExecutionHandler handler) {\n        if (corePoolSize < 0 ||\n            maximumPoolSize <= 0 ||\n            maximumPoolSize < corePoolSize ||\n            keepAliveTime < 0)\n            throw new IllegalArgumentException();\n        if (workQueue == null || threadFactory == null || handler == null)\n            throw new NullPointerException();\n        this.corePoolSize = corePoolSize;\n        this.maximumPoolSize = maximumPoolSize;\n        this.workQueue = workQueue;\n        this.keepAliveTime = unit.toNanos(keepAliveTime);\n        this.threadFactory = threadFactory;\n        this.handler = handler;\n    }\n```\n\n函数参数含义如下：\n\n```java\nint corePoolSize,\t//指定了线程池中的线程数量\nint maximumPoolSize,\t//指定了线程池中的最大线程数量\nlong keepAliveTime,\t//当线程池线程超过了corepoolsize时， 多余的空闲线程存活时间\nTimeUnit unit,\t//keepalivetime的单位\nBlockingQueue<Runnable> workQueue,\t//任务队列，被提交但尚未被执行的任务\nThreadFactory threadFactory,\t//线程工厂，用于创建线程，一般用默认的即可\nRejectedExecutionHandler handler\t//拒绝策略，当任务太多来不及更新，如何拒绝任务\n```\n\n对workQueue和handler进行详细说明。\n\n参数workQueue值被提交但尚未被执行的任务队列，它是一个BlockingQueue接口的对象，仅用于存放runable对象。根据队列功能分类，可使用一下几种BlockingQueue。\n\n- 直接提交的队列。该功能由SynchronousQueue对象提供。SynchronousQueue是一个特殊的BLockingQueue。SynchronousQueue没有容量，提交的任务不会被真实的保存，而总是将新任务提交给线程执行。如果没有空闲的线程，则尝试创建新的线程，如果线程数量达到了最大值，则执行拒绝策略。\n\n- 有界的任务队列。有界的任务队列可以使用ArrayBlockingQueue实现。\n\n  ```java\n  public ArrayBlockingQueue(int capacity)\n  ```\n\n  当使用有界的任务队列时，若有新的任务需要执行，如果线程池的线程数量小于corePoolSize，则会优先创建新的线程，若大于，则会将新任务加入等待队列。若等待队列已满，无法加入，则在总线程数不大于maximumPoolSize的前提下，创建新的线程执行任务。若大于maximumPoolSize，执行拒绝策略。可见，当任务队列装满时，才可能将线程数量提升到corePoolSize以上。\n\n- 无界的任务队列。无界的任务队列可以通过LinkedBlockingQueue类实现。除非系统资源耗尽，否则无界的任务队列不会出现任务入队失败的情况。当有新的任务到来，系统的线程数小于corePoolSize时，线程池会产生新的线程执行任务，但当线程数达到corePoolSize后，线程数不会增加，任务直接进入队列等待。\n\n- 优先任务队列。优先任务对立是带有执行优先级的队列。它通过PriorityBlockingQueue实现，可以控制任务的执行先后顺序。它是一个特殊的无界队列，根据任务自身的优先级来先后执行。\n\n### 拒绝策略\n\nJDK内置了四种拒绝策略：\n\n- AbortPolicy：该策略会直接抛出异常，阻止系统正常工作\n- CallerRunsPolicy：只要线程池未关闭，该策略直接在调用者线程中，运行当前被丢弃的任务\n- DiscardOldestPolicy：丢弃最老的一个任务，也就是即将被执行的一个任务，并尝试再次提交当前任务\n- DiscardPolicy：默默地丢弃无法处理的任务\n\n可以自定义扩展RejectExecutionHandler接口。\n\n### 自定义线程创建 ThreadFactory\n\n线程从何而来？答案就是ThreadFactory。\n\nThreadFactory是一个接口，它只有一个方法，用来创建线程：\n\n```java\nThread newThread(Runnable r);\n```\n\n### 扩展线程池\n\n情景：我们想监控每个任务执行开始和结束的时间\n\nThreadPoolExecutor是一个可扩展的线程池。它提供了beforeExecute()和afterExecute()、terminated()三个接口对线程池进行控制。\n\n### 分而治之 fork/join框架\n\n对于线程池的优化，提交的任务和线程数量并不是一对一的关系。在绝大多数情况下，一个物理线程实际上是需要处理多个逻辑任务的。因此，每个线程必然需要拥有一个任务队列。因此，在实际执行过程中，可能遇到线程A已经把自己的任务做完了，而线程B还有一堆任务等着处理。此时，线程A就会帮助线程B，从线程B的任务队列中拿一个任务过来处理，尽可能地达到平衡。注意：一个线程试图帮助别人时，总是从任务队列的底部开始拿数据，而线程试图执行自己的任务时，则是从相反的顶部拿，避免数据竞争。\n\n```java\npublic <T> ForkJoinTask<T> submit(ForkJoinTask<T> task) {\n        return externalSubmit(task);\n    }\n```\n\nForkJoinTask有两个子类，RecursiveAction和RecursiveTask，分别表示无返回值和有返回值的任务。\n\n\n\n\n\n## JDK并发容器\n\n- ConcurrentHashmap 线程安全的hashmap\n- CopyOnWriteArrayList 在读多写少的情况下，性能好\n- ConcurrentLinkedQueue 高效的并发队列，线程安全LinkedList\n- BlockingQueue 这是一个接口，表示阻塞队列，JDK使用数组、链表等方式实现了这个接口\n- ConcurrentSkipListMap 跳表的实现\n\n\n\n\n\n# 锁的优化及注意事项\n\n## 有助于优化锁的几点建议\n\n- 减小锁的持有时间\n- 减小锁的粒度\n- 读写分离锁来替换独占锁\n- 锁分离\n- 锁粗化","tags":["多线程,JUC"]},{"title":"Redis 相关","url":"/2019/03/20/20190325/","content":"** {{ title }}：** <Excerpt in index | 首页摘要>\n前几天面试准备的Redis\n<!-- more -->\n<The rest of contents | 余下全文>\n# Redis\n- Redis与Memcached的区别与比较\n\n  1 、Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，zset，hash等数据结构的存储。memcache支持简单的数据类型，String。\n\n  2 、Redis支持数据的备份，即master-slave模式的数据备份。\n\n  3 、Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而Memecache把数据全部存在内存之中\n\n  4、 redis的速度比memcached快很多\n\n  5、Memcached是多线程，非阻塞IO复用的网络模型；Redis使用单线程的IO复用模型。\n\n- Redis常见的数据结构\n\n  String\n\n  String数据结构是简单的key-value类型，value其实不仅可以是String，也可以是数字。  常规key-value缓存应用;常规计数：微博数，粉丝数等。\n\n  Hash\n\n  Hash是一个string类型的field和value的映射表，hash特别适合用于存储对象。 比如我们可以Hash数据结构来存储用户信息，商品信息等等。\n\n  List\n\n  list就是链表，Redis list的应用场景非常多，也是Redis最重要的数据结构之一，比如微博的关注列表，粉丝列表，最新消息排行等功能都可以用Redis的list结构来实现。\n\n  Set\n\n  set对外提供的功能与list类似是一个列表的功能，特殊之处在于set是可以自动排重的。\n\n  在微博应用中，可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。Redis可以非常方便的实现如共同关注、共同喜好、二度好友等功能。\n\n  SortedSet\n\n  和set相比，sorted set增加了一个权重参数score，使得集合中的元素能够按score进行有序排列。举例： 在直播系统中，实时排行信息包含直播间在线用户列表，各种礼物排行榜，弹幕消息（可以理解为按消息维度的消息排行榜）等信息，适合使用Redis中的SortedSet结构进行存储。\n\n\n\n- 从宏观角度回顾一下Redis实现高可用相关的技术。它们包括：持久化、复制、哨兵和集群，其主要作用和解决的问题是：\n  - 持久化：持久化是最简单的高可用方法(有时甚至不被归为高可用的手段)，主要作用是数据备份，即将数据存储在硬盘，保证数据不会因进程退出而丢失。\n  - 复制：复制是高可用Redis的基础，哨兵和集群都是在复制基础上实现高可用的。复制主要实现了数据的多机备份，以及对于读操作的负载均衡和简单的故障恢复。缺陷：故障恢复无法自动化；写操作无法负载均衡；存储能力受到单机的限制。\n  - 哨兵：在复制的基础上，哨兵实现了自动化的故障恢复。缺陷：写操作无法负载均衡；存储能力受到单机的限制。\n  - 集群：通过集群，Redis解决了写操作无法负载均衡，以及存储能力受到单机限制的问题，实现了较为完善的高可用方案。\n\n\n\n- redis有哪些数据淘汰策略？？？\n\n  volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰 \n\n  volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰 \n\n  volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 \n\n  allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰 \n\n  allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 \n\n  no-enviction（驱逐）：禁止驱逐数据\n\n  *默认的内存策略是noeviction，在Redis中LRU算法是一个近似算法，默认情况下，Redis随机挑选5个键，并且从中选取一个最近最久未使用的key进行淘汰，在配置文件中可以通过maxmemory-samples的值来设置redis需要检查key的个数,但是栓查的越多，耗费的时间也就越久,但是结构越精确(也就是Redis从内存中淘汰的对象未使用的时间也就越久~),设置多少，综合权衡吧~~~*\n\n## Redis 持久化\n\nredis 支持两种持久化方式，一种是 Snapshotting（快照）也是默认方式，另一种是 Append-only file（缩写 aof）的方式。\n\n快照是默认的持久化方式。这种方式是就是将内存中数据以快照的方式写入到二进制文件中,默认的文件名为dump.rdb。可以通过配置设置自动做快照持久化的方式。\n\n```\n1.redis 调用 fork,现在有了子进程和父进程。\n2. 父进程继续处理 client 请求，子进程负责将内存内容写入到临时文件。由于 os 的实时复制机制（ copy on write)父子进程会共享相同的物理页面，当父进程处理写请求时 os 会为父进程要修改的页面创建副本，而不是写共享的页面。所以子进程地址空间内的数据是 fork时刻整个数据库的一个快照。\n3.当子进程将快照写入临时文件完毕后，用临时文件替换原来的快照文件，然后子进程退出。client 也可以使用 save 或者 bgsave 命令通知 redis 做一次快照持久化。 save 操作是在主线程中保存快照的，由于 redis 是用一个主线程来处理所有 client 的请求，这种方式会阻塞所有client 请求。所以不推荐使用。另一点需要注意的是，每次快照持久化都是将内存数据完整写入到磁盘一次，并不是增量的只同步变更数据。如果数据量大的话，而且写操作比较多，必然会引起大量的磁盘 io 操作，可能会严重影响性能。\n```\n\n由于快照方式是在一定间隔时间做一次的，所以如果 redis 意外 down 掉的话，就会丢失最后一次快照后的所有修改。\n\n如果应用要求不能丢失任何修改的话，可以采用 aof 持久化方式。下面介绍 Append-only file:aof 比快照方式有更好的持久化性，是由于在使用 aof 持久化方式时,redis 会将每一个收到的写命令都通过 write 函数追加到文件中(默认是 appendonly.aof)。当 redis 重启时会通过重新执行文件中保存的写命令来在内存中重建整个数据库的内容。当然由于 os 会在内核中缓存 write 做的修改，所以可能不是立即写到磁盘上。这样 aof 方式的持久化也还是有可能会丢失部分修改。不过我们可以通过配置文件告诉 redis 我们想要通过 fsync 函数强制 os 写入到磁盘的时机。\n\n## 主从复制\n\n全量复制：\n\nRedis全量复制一般发生在Slave初始化阶段，这时Slave需要将Master上的所有数据都复制一份。具体步骤如下： \n\n　　1）从服务器连接主服务器，发送SYNC命令； \n\n　　2）主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执行的所有写命令； \n\n　　3）主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令； \n\n　　4）从服务器收到快照文件后丢弃所有旧数据，载入收到的快照； \n\n　　5）主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令； \n\n　　6）从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令； \n\n增量同步：\n\nRedis增量复制是指Slave初始化后开始正常工作时主服务器发生的写操作同步到从服务器的过程。 \n\n增量复制的过程主要是主服务器每执行一个写命令就会向从服务器发送相同的写命令，从服务器接收并执行收到的写命令。\n\n主从复制策略：\n\n主从刚刚连接的时候，进行全量同步；全同步结束后，进行增量同步。当然，如果有需要，slave 在任何时候都可以发起全量同步。redis 策略是，无论如何，首先会尝试进行增量同步，如不成功，要求从机进行全量同步。\n\n## 哨兵\n\n关于哨兵的原理，关键是了解以下几个概念。\n\n（1）定时任务：每个哨兵节点维护了3个定时任务。定时任务的功能分别如下：通过向主从节点发送info命令获取最新的主从结构；通过发布订阅功能获取其他哨兵节点的信息；通过向其他节点发送ping命令进行心跳检测，判断是否下线。\n\n（2）主观下线：在心跳检测的定时任务中，如果其他节点超过一定时间没有回复，哨兵节点就会将其进行主观下线。顾名思义，主观下线的意思是一个哨兵节点“主观地”判断下线；与主观下线相对应的是客观下线。\n\n（3）客观下线：哨兵节点在对主节点进行主观下线后，会通过sentinel is-master-down-by-addr命令询问其他哨兵节点该主节点的状态；如果判断主节点下线的哨兵数量达到一定数值，则对该主节点进行客观下线。\n\n**需要特别注意的是，客观下线是主节点才有的概念；如果从节点和哨兵节点发生故障，被哨兵主观下线后，不会再有后续的客观下线和故障转移操作。**\n\n（4）选举领导者哨兵节点：当主节点被判断客观下线以后，各个哨兵节点会进行协商，选举出一个领导者哨兵节点，并由该领导者节点对其进行故障转移操作。\n\n监视该主节点的所有哨兵都有可能被选为领导者，选举使用的算法是Raft算法；Raft算法的基本思路是先到先得：即在一轮选举中，哨兵A向B发送成为领导者的申请，如果B没有同意过其他哨兵，则会同意A成为领导者。选举的具体过程这里不做详细描述，一般来说，哨兵选择的过程很快，谁先完成客观下线，一般就能成为领导者。\n\n（5）故障转移：选举出的领导者哨兵，开始进行故障转移操作，该操作大体可以分为3个步骤：\n\n- 在从节点中选择新的主节点：选择的原则是，首先过滤掉不健康的从节点；然后选择优先级最高的从节点(由slave-priority指定)；如果优先级无法区分，则选择复制偏移量最大的从节点；如果仍无法区分，则选择runid最小的从节点。\n- 更新主从状态：通过slaveof no one命令，让选出来的从节点成为主节点；并通过slaveof命令让其他节点成为其从节点。\n- 将已经下线的主节点(即6379)设置为新的主节点的从节点，当6379重新上线后，它会成为新的主节点的从节点。","tags":["Redis"]},{"title":"分布式的一些算法","url":"/2019/03/20/20190326/","content":"** {{ title }}：** <Excerpt in index | 首页摘要>\n入门分布式，看了一些分布式的算法……\n<!-- more -->\n<The rest of contents | 余下全文>\n# CAP\n\nCAP理论：一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项。\n\n### Consistency 一致性\n\n一致性指“`all nodes see the same data at the same time`”，即更新操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致，所以，一致性，说的就是数据一致性。\n\n### Availability 可用性\n\n可用性指“`Reads and writes always succeed`”，即服务一直可用，而且是正常响应时间。\n\n### Partition Tolerance分区容错性\n\n分区容错性指“`the system continues to operate despite arbitrary message loss or failure of part of the system`”，即分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务。\n\n# BASE\n\nBASE是指基本可用（Basically Available）、软状态（ Soft State）、最终一致性（ Eventual Consistency）。\n\n### 基本可用（Basically Available）\n\n基本可用是指分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用。\n\n电商大促时，为了应对访问量激增，部分用户可能会被引导到降级页面，服务层也可能只提供降级服务。这就是损失部分可用性的体现。\n\n### 软状态（ Soft State）\n\n软状态是指允许系统存在中间状态，而该中间状态不会影响系统整体可用性。分布式存储中一般一份数据至少会有三个副本，允许不同节点间副本同步的延时就是软状态的体现。mysql replication的异步复制也是一种体现。\n\n### 最终一致性（ Eventual Consistency）\n\n最终一致性是指系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。弱一致性和强一致性相反，最终一致性是弱一致性的一种特殊情况。\n\n# 2PC\n\n二阶段提交协议主要分为来个阶段：准备阶段和提交阶段。\n\n在日常生活中其实是有很多事都是这种二阶段提交的，比如西方婚礼中就经常出现这种场景：\n\n> 牧师：”你愿意娶这个女人吗?爱她、忠诚于她，无论她贫困、患病或者残疾，直至死亡。Doyou(你愿意吗)?”\n>\n> 新郎：”Ido(我愿意)!”\n>\n> 牧师：”你愿意嫁给这个男人吗?爱他、忠诚于他，无论他贫困、患病或者残疾，直至死亡。Doyou(你愿意吗)?”\n>\n> 新娘：”Ido(我愿意)!”\n>\n> 牧师：现在请你们面向对方，握住对方的双手，作为妻子和丈夫向对方宣告誓言。\n>\n> 新郎：我——某某某，全心全意娶你做我的妻子，无论是顺境或逆境，富裕或贫穷，健康或疾病，快乐或忧愁，我都将毫无保留地爱你，我将努力去理解你，完完全全信任你。我们将成为一个整体，互为彼此的一部分，我们将一起面对人生的一切，去分享我们的梦想，作为平等的忠实伴侣，度过今后的一生。\n>\n> 新娘：我全心全意嫁给你作为你的妻子，无论是顺境或逆境，富裕或贫穷，健康或疾病，快乐或忧愁，我都将毫无保留的爱你，我将努力去理解你，完完全全信任你，我们将成为一个整体，互为彼此的一部分，我们将一起面对人生的一切，去分享我们的梦想，作为平等的忠实伴侣，度过今后的一生。\n\n首先协调者（牧师）会询问两个参与者（二位新人）是否能执行事务提交操作（愿意结婚）。如果两个参与者能够执行事务的提交，先执行事务操作，然后返回YES，如果没有成功执行事务操作，就返回NO。\n\n当协调者接收到所有的参与者的反馈之后，开始进入事务提交阶段。如果所有参与者都返回YES，那就发送COMMIT请求，如果有一个人返回NO，那就返送roolback请求。\n\n- 2PC协议中，如果出现协调者和参与者都挂了的情况，有可能导致数据不一致。\n\n第二阶段协调者和参与者挂了，挂了的这个参与者在挂之前已经执行了操作。但是由于他挂了，没有人知道他执行了什么操作。\n\n- 这种情况下，新的协调者被选出来之后，如果他想负起协调者的责任的话他就只能按照之前那种情况来执行commit或者roolback操作。这样新的协调者和所有没挂掉的参与者就保持了数据的一致性，我们假定他们执行了commit。但是，这个时候，那个挂掉的参与者恢复了怎么办，因为他之前已经执行完了之前的事务，如果他执行的是commit那还好，和其他的机器保持一致了，万一他执行的是roolback操作那？这不就导致数据的不一致性了么？虽然这个时候可以再通过手段让他和协调者通信，再想办法把数据搞成一致的，但是，这段时间内他的数据状态已经是不一致的了！\n\n------\n\n# 3PC\n\n3PC最关键要解决的就是协调者和参与者同时挂掉的问题，所以3PC把2PC的准备阶段再次一分为二，这样三阶段提交就有`CanCommit`、`PreCommit`、`DoCommit`三个阶段。在第一阶段，只是询问所有参与者是否可可以执行事务操作，并不在本阶段执行事务操作。当协调者收到所有的参与者都返回YES时，在第二阶段才执行事务操作，然后在第三阶段在执行commit或者rollback。\n\n这里再举一个生活中类似三阶段提交的例子：\n\n> 班长要组织全班同学聚餐，由于大家毕业多年，所以要逐个打电话敲定时间，时间初定10.1日。然后开始逐个打电话。\n>\n> 班长：小A，我们想定在10.1号聚会，你有时间嘛？有时间你就说YES，没有你就说NO，然后我还会再去问其他人，具体时间地点我会再通知你，这段时间你可先去干你自己的事儿，不用一直等着我。（**协调者询问事务是否可以执行，这一步不会锁定资源**）\n>\n> 小A：好的，我有时间。（**参与者反馈**）\n>\n> 班长：小B，我们想定在10.1号聚会……不用一直等我。\n>\n> 班长收集完大家的时间情况了，一看大家都有时间，那么就再次通知大家。（**协调者接收到所有YES指令**）\n>\n> 班长：小A，我们确定了10.1号聚餐，你要把这一天的时间空出来，这一天你不能再安排其他的事儿了。然后我会逐个通知其他同学，通知完之后我会再来和你确认一下，还有啊，如果我没有特意给你打电话，你就10.1号那天来聚餐就行了。对了，你确定能来是吧？（**协调者发送事务执行指令，这一步锁住资源。如果由于网络原因参与者在后面没有收到协调者的命令，他也会执行commit**）\n>\n> 小A顺手在自己的日历上把10.1号这一天圈上了，然后跟班长说，我可以去。（**参与者执行事务操作，反馈状态**）\n>\n> 班长：小B，我们觉得了10.1号聚餐……你就10.1号那天来聚餐就行了。\n>\n> 班长通知完一圈之后。所有同学都跟他说：”我已经把10.1号这天空出来了”。于是，他在10.1号这一天又挨个打了一遍电话告诉他们：嘿，现在你们可以出门拉。。。。（**协调者收到所有参与者的ACK响应，通知所有参与者执行事务的commit**）\n>\n> 小A，小B：我已经出门拉。（**执行commit操作，反馈状态**）\n\n- 3PC为什么比2PC好？？\n\n**简单概括一下就是，如果挂掉的那台机器已经执行了commit，那么协调者可以从所有未挂掉的参与者的状态中分析出来，并执行commit。如果挂掉的那个参与者执行了rollback，那么协调者和其他的参与者执行的肯定也是rollback操作。**\n\n- 3PC的问题\n\n在doCommit阶段，如果参与者无法及时接收到来自协调者的doCommit或者rebort请求时，会在等待超时之后，会继续进行事务的提交。所以，由于网络原因，协调者发送的abort响应没有及时被参与者接收到，那么参与者在等待超时之后执行了commit操作。这样就和其他接到abort命令并执行回滚的参与者之间存在数据不一致的情况。\n\n# PAXOS\n\n解决的问题：在一个可能发生异常的分布式系统中如何就某个值达成一致，让整个集群的节点对某个值的变更达成一致\n\n任何一个节点都可以提出要修改某个数据的提案,是否通过这个提案取决于这个集群中是否有超过半数的节点同意（所以节点数总是单数）—— 版本标记。虽然一致性，但是只能对一个操作进行操作啊？？\n\n当一个Server接收到比当前版本号小的提案时，则拒绝。当收到比当前大的版本号的提案时，则锁定资源，进行修改，返回OK.   也就是说收到超过一半的最大版本的提案才算成功。\n\n核心思想：\n\n在抢占式访问权的基础上引入多个acceptor，也就是说当一个版本号更大的提案可以剥夺版本号已经获取的锁。\n\n后者认同前者的原则：\n\n> 在肯定旧epoch 无法生成确定性取值时，新的 epoch 会提交自己的valu\n>\n> 一旦 旧epoch形成确定性取值，新的 epoch肯定可以获取到此取值，并且会认同此取值，不会被破坏。\n\n# ZAB \n\n定义：原子广播协议 ZAB 是一致性协议，Zookeeper 把其作为数据一致性的算法。ZAB 是在 Paxos 算法基础上进行扩展而来的。Zookeeper 使用单一主进程 Leader用于处理客户端所有事务请求，采用 ZAB 协议将服务器状态以事务形式广播到所有 Follower 上，由于事务间可能存在着依赖关系，ZAB协议保证 Leader 广播的变更序列被顺序的处理，一个状态被处理那么它所依赖的状态也已经提前被处理\n\n核心思想：保证任意时刻只有一个节点是Leader，所有更新事务由Leader发起去更新所有副本 Follower，更新时用的是 两段提交协议，只要多数节点 prepare 成功，就通知他们commit。各个follower 要按当初 leader 让他们 prepare 的顺序来 apply 事务\n\n协议状态\n\nLooking:系统刚启动时 或者 Leader 崩溃后正处于选举状态\n\nFollowing：Follower 节点所处的状态，Follower与 Leader处于数据同步状态\n\nLeading：Leader 所处状态，当前集群中有一个 Leader 为主进程\n\nZooKeeper启动时所有节点初始状态为Looking，这时集群会尝试选举出一个Leader节点，选举出的Leader节点切换为Leading状态；当节点发现集群中已经选举出Leader则该节点会切换到Following状态，然后和Leader节点保持同步；当Follower节点与Leader失去联系时Follower节点则会切换到Looking状态，开始新一轮选举；在ZooKeeper的整个生命周期中每个节点都会在Looking、Following、Leading状态间不断转换。\n\n\n\n选举出Leader节点后 ZAB 进入原子广播阶段，这时Leader为和自己同步每个节点 Follower 创建一个操作序列，一个时期一个 Follower 只能和一个Leader保持同步\n\n# Raft\n\n在Raft中，任何时候一个服务器可以扮演下面角色之一：\n\n1. Leader: 处理所有客户端交互，日志复制等，一般一次只有一个Leader.\n2. Follower: 类似选民，完全被动\n3. Candidate候选人: 类似Proposer律师，可以被选为一个新的领导人。\n\nRaft阶段分为两个，首先是选举过程，然后在选举出来的领导人带领进行正常操作，比如日志复制等。\n\n- 任何一个服务器都可以成为一个候选者Candidate，它向其他服务器Follower发出要求选举自己的请求：\n- 其他服务器同意了，发出OK。注意如果在这个过程中，有一个Follower宕机，没有收到请求选举的要求，因此候选者可以自己选自己，只要达到N/2 + 1 的大多数票，候选人还是可以成为Leader的。\n- 这样这个候选者就成为了Leader领导人，它可以向选民也就是Follower们发出指令，比如进行日志复制。\n- 以后通过心跳进行日志复制的通知\n- 如果一旦这个Leader当机崩溃了，那么Follower中有一个成为候选者，发出邀票选举。\n- Follower同意后，其成为Leader，继续承担日志复制等指导工作：\n\nSplite Vote是因为如果同时有两个候选人向大家邀票，这时通过类似加时赛来解决，两个候选者在一段timeout比如300ms互相不服气的等待以后，因为双方得到的票数是一样的，一半对一半，那么在300ms以后，再由这两个候选者发出邀票，这时同时的概率大大降低，那么首先发出邀票的的候选者得到了大多数同意，成为领导者Leader，而另外一个候选者后来发出邀票时，那些Follower选民已经投票给第一个候选者，不能再投票给它，它就成为落选者了，最后这个落选者也成为普通Follower一员了。\n\nhttps://blog.csdn.net/lxlmycsdnfree/article/details/78984752\n\n","tags":["分布式"]},{"title":"Spring 相关","url":"/2019/03/20/20190323/","content":"** {{ title }}：** <Excerpt in index | 首页摘要>\n总结的一些Spring\n<!-- more -->\n<The rest of contents | 余下全文>\n# Spring Bean 的生命周期\n\n- 实例化bean对象(通过构造方法或者工厂方法)\n- 设置对象属性(setter等)（依赖注入）\n- 如果Bean实现了BeanNameAware接口，工厂调用Bean的setBeanName()方法传递Bean的ID。（和下面的一条均属于检查Aware接口）\n- 如果Bean实现了BeanFactoryAware接口，工厂调用setBeanFactory()方法传入工厂自身\n- 将Bean实例传递给Bean的前置处理器的postProcessBeforeInitialization(Object bean, String beanname)方法\n  调用Bean的初始化方法\n- 将Bean实例传递给Bean的后置处理器的postProcessAfterInitialization(Object bean, String beanname)方法\n- 使用Bean\n- 容器关闭之前，调用Bean的销毁方法\n\n# Bean的作用域\n\nSpring 3中为Bean定义了5中作用域，分别为singleton（单例）、prototype（原型）、request、session和global session，5种作用域说明如下：\n\n1. singleton：单例模式，Spring IoC容器中只会存在一个共享的Bean实例，无论有多少个Bean引用它，始终指向同一对象。Singleton作用域是Spring中的缺省作用域，也可以显示的将Bean定义为singleton模式，配置为：\n   - <bean id=\"userDao\" class=\"com.ioc.UserDaoImpl\" scope=\"singleton\"/>\n2. prototype:原型模式，每次通过Spring容器获取prototype定义的bean时，容器都将创建一个新的Bean实例，每个Bean实例都有自己的属性和状态，而singleton全局只有一个对象。根据经验，对有状态的bean使用prototype作用域，而对无状态的bean使用singleton作用域。\n3. request：在一次Http请求中，容器会返回该Bean的同一实例。而对不同的Http请求则会产生新的Bean，而且该bean仅在当前Http Request内有效。\n   - <bean id=\"loginAction\" class=\"com.cnblogs.Login\" scope=\"request\"/>,针对每一次Http请求，Spring容器根据该bean的定义创建一个全新的实例，且该实例仅在当前Http请求内有效，而其它请求无法看到当前请求中状态的变化，当当前Http请求结束，该bean实例也将会被销毁。\n4. session：在一次Http Session中，容器会返回该Bean的同一实例。而对不同的Session请求则会创建新的实例，该bean实例仅在当前Session内有效。\n   - <bean id=\"userPreference\" class=\"com.ioc.UserPreference\" scope=\"session\"/>,同Http请求相同，每一次session请求创建新的实例，而不同的实例之间不共享属性，且实例仅在自己的session请求内有效，请求结束，则实例将被销毁。\n5. global Session：在一个全局的Http Session中，容器会返回该Bean的同一个实例，仅在使用portlet context时有效。\n\n# Bean自动装配的区别\n\n在Spring框架中共有5种自动装配。\n\n1. no：这是Spring框架的默认设置，在该设置下自动装配是关闭的，开发者需要自行在bean定义中用标签明确的设置依赖关系。\n2. byName：该选项可以根据bean名称设置依赖关系。当向一个bean中自动装配一个属性时，容器将根据bean的名称自动在在配置文件中查询一个匹配的bean。如果找到的话，就装配这个属性，如果没找到的话就报错。\n3. byType：该选项可以根据bean类型设置依赖关系。当向一个bean中自动装配一个属性时，容器将根据bean的类型自动在在配置文件中查询一个匹配的bean。如果找到的话，就装配这个属性，如果没找到的话就报错。\n4. constructor：造器的自动装配和byType模式类似，但是仅仅适用于与有构造器相同参数的bean，如果在容器中没有找到与构造器参数类型一致的bean，那么将会抛出异常。\n5. autodetect：该模式自动探测使用构造器自动装配或者byType自动装配。首先，首先会尝试找合适的带参数的构造器，如果找到的话就是用构造器自动装配，如果在bean内部没有找到相应的构造器或者是无参构造器，容器就会自动选择byTpe的自动装配方式。\n\n# spring（数据库）事务隔离级别分为四种（级别递减）：\n\n1、Serializable （串行化）：最严格的级别，事务串行执行，资源消耗最大；\n\n2、REPEATABLE READ（重复读） ：保证了一个事务不会修改已经由另一个事务读取但未提交（回滚）的数据。避免了“脏读取”和“不可重复读取”的情况，但不能避免“幻读”，但是带来了更多的性能损失。\n\n3、READ COMMITTED （提交读）：大多数主流数据库的默认事务等级，保证了一个事务不会读到另一个并行事务已修改但未提交的数据，避免了“脏读取”，但不能避免“幻读”和“不可重复读取”。该级别适用于大多数系统。\n\n4、Read Uncommitted（未提交读） ：事务中的修改，即使没有提交，其他事务也可以看得到，会导致“脏读”、“幻读”和“不可重复读取”。\n\n脏读、不可重复读、幻读：\n\n也许有很多读者会对上述隔离级别中提及到的 脏读、不可重复读、幻读 的理解有点吃力，我在这里尝试使用通俗的方式来解释这三种语义：\n\n脏读：所谓的脏读，其实就是读到了别的事务回滚前的脏数据。比如事务B执行过程中修改了数据X，在未提交前，事务A读取了X，而事务B却回滚了，这样事务A就形成了脏读。\n\n也就是说，当前事务读到的数据是别的事务想要修改成为的但是没有修改成功的数据。\n\n不可重复读：事务A首先读取了一条数据，然后执行逻辑的时候，事务B将这条数据改变了，然后事务A再次读取的时候，发现数据不匹配了，就是所谓的不可重复读了。\n\n也就是说，当前事务先进行了一次数据读取，然后再次读取到的数据是别的事务修改成功的数据，导致两次读取到的数据不匹配，也就照应了不可重复读的语义。\n\n幻读：事务A首先根据条件索引得到N条数据，然后事务B改变了这N条数据之外的M条或者增添了M条符合事务A搜索条件的数据，导致事务A再次搜索发现有N+M条数据了，就产生了幻读。\n\n也就是说，当前事务读第一次取到的数据比后来读取到数据条目少。\n\n不可重复读和幻读比较：\n\n两者有些相似，但是前者针对的是update或delete，后者针对的insert。\n\n# Spring事务传播\n\nSpring事务的传播行为定义了外层方法[注1]调用带有@Transactional的当前方法时，事务如何进行传播的规则，共有7种类型： \n（1）PROPAGATION.REQUIRED(默认) \n如果外层方法有事务，则当前方法加入外层事务；如果外层方法没有事务，则当前方法新建一个事务。 \n（2）PROPAGATION.REQUIRES_NEW \n当前方法总是开启一个新的事务，如果外层方法有事务，则将外层事务挂起，先执行当前方法的事务（外层事务和当前方法的事务是两个不同的事务）。 \n当当前方法发生回滚并抛出RuntimeException时，如果该异常被捕获，则外层方法的事务不会因此回滚；如果该异常没有被捕获，则外层方法的事务就会因此而回滚。 \n当外层方法发生回滚时，如果其回滚发生在当前方法前，则当前方法得不到执行；如果其回滚发生在当前方法之后，则当前方法不会因此而回滚。 \n（3）PROPAGATION.NESTED \n如果外层方法没事务，则当前方法新建一个事务；如果外层方法有事务，则把当前方法当成外层事务的一部分（使用savepoint实现），外层方法事务的rolback或者commit都会影响当前方法[注2]，而当前方法的rolback不会导致外层事务回滚，除非rollback过程抛出了RuntimeException且该异常没有被捕获。 \n（4）PROPAGATION.SUPPORTS \n如果外层方法没事务，那当前方法就按普通方法执行；如果外层方法有事务，则使用外层方法的事务。 \n（5）PROPAGATION.NOT_SUPPORTED \n当前方法总是非事务地执行，如果外层方法有事务则把事务挂起，当前方法还是以普通方法执行。 \n（6）PROPAGATION.NEVER \n如果外层方法没事务，那当前方法就按普通方法执行；如果外层方法有事务，则当前方法抛出异常。 \n（7）PROPAGATION.MANDATORY 如果外层方法没事务，则当前方法就会抛出异常；如果外层方法有事务，则当前方法使用外层事务。\n\n# DispatherServlet\n\n在整个SpringMVC框架中，DispatherServlet吃于核心位置，它负责协调和组织不同组建完成请求处理并返回响应工作。\n\nSpringMVC的请求处理大致流程：\n\n1. Tomcat 启动，对 DispatcherServlet 进行实例化，然后调用它的 init() 方法进行初始化，在这个初始化过程中完成了\n2. 对 web.xml 中初始化参数的加载；建立 WebApplicationContext (SpringMVC的IOC容器)；进行组件的初始化\n3. 客户端发出请求，由 Tomcat 接收到这个请求，如果匹配 DispatcherServlet 在 web.xml 中配置的映射路径，Tomcat 就将请求转交给 DispatcherServlet 处理\n4. DispatcherServlet 从容器中取出所有 HandlerMapping 实例（每个实例对应一个 HandlerMapping 接口的实现类）并遍历，每个 HandlerMapping 会根据请求信息，通过自己实现类中的方式去找到处理该请求的 Handler (执行程序，如Controller中的方法)，并且将这个 Handler 与一堆 HandlerInterceptor (拦截器) 封装成一个 HandlerExecutionChain 对象，一旦有一个 HandlerMapping 可以找到 Handler 则退出循环\n5. DispatcherServlet 取出 HandlerAdapter 组件，根据已经找到的 Handler，再从所有 HandlerAdapter 中找到可以处理该 Handler 的 HandlerAdapter 对象\n6. 执行 HandlerExecutionChain 中所有拦截器的 preHandler() 方法，然后再利用 HandlerAdapter 执行 Handler ，执行完成得到 ModelAndView，再依次调用拦截器的 postHandler() 方法\n7. 利用 ViewResolver 将 ModelAndView 或是 Exception（可解析成 ModelAndView）解析成 View，然后 View 会调用 render() 方法再根据 ModelAndView 中的数据渲染出页面\n8. 最后再依次调用拦截器的 afterCompletion() 方法，这一次请求就结束了\n\nDispacherServlet源码分析：\n\nDispatcherServlet 继承自 HttpServlet，它遵循 Servlet 里的“init-service-destroy”三个阶段。\n\n1、初始化\n\nDispatcherServlet 的 init() 方法在其父类 **HttpServletBean** 中实现的，它覆盖了 GenericServlet 的 init() 方法，主要作用是加载 web.xml 中 DispatcherServlet 的 <init-param> 配置，并调用子类的初始化。\n\n在 HttpServletBean 的 init() 方法中调用了 initServletBean() 这个方法，它是在 **FrameworkServlet** 类中实现的，主要作用是建立 WebApplicationContext 容器（有时也称上下文），并加载 SpringMVC 配置文件中定义的 Bean 到改容器中，最后将该容器添加到 ServletContext 中。\n\nWebApplicationContext 继承于 ApplicationContext 接口，从容器中可以获取当前应用程序环境信息，它也是 SpringMVC 的 IOC 容器。\n\n建立好 WebApplicationContext(上下文) 后，通过 onRefresh(ApplicationContext context) 方法回调，进入 DispatcherServlet 类中。onRefresh() 方法，提供 SpringMVC 的初始化。\n\n```java\n@Override\n    protected void onRefresh(ApplicationContext context) {\n        initStrategies(context);\n    }\n    protected void initStrategies(ApplicationContext context) {\n        initMultipartResolver(context);\n        initLocaleResolver(context);\n        initThemeResolver(context);\n        initHandlerMappings(context);\n        initHandlerAdapters(context);\n        initHandlerExceptionResolvers(context);\n        initRequestToViewNameTranslator(context);\n        initViewResolvers(context);\n        initFlashMapManager(context);\n    }\n```\n\n\n\ninitHandlerMappings() 方法从 SpringMVC 的容器及 Spring 的容器中查找所有的 HandlerMapping 实例，并把它们放入到 handlerMappings 这个 list 中。这个方法并不是对 HandlerMapping 实例的创建，HandlerMapping 实例是在上面 WebApplicationContext 容器初始化，即 SpringMVC 容器初始化的时候创建的。\n\n```java\nprivate void initHandlerMappings(ApplicationContext context) {\n    this.handlerMappings = null;\n    if (this.detectAllHandlerMappings) {\n        // 从 SpringMVC 的 IOC 容器及 Spring 的 IOC 容器中查找 HandlerMapping 实例\n        Map<String, HandlerMapping> matchingBeans =\n        　　　　BeanFactoryUtils.beansOfTypeIncludingAncestors(context, HandlerMapping.class, true, false);\n        if (!matchingBeans.isEmpty()) {\n            this.handlerMappings = new ArrayList<HandlerMapping>(matchingBeans.values());\n            // 按一定顺序放置 HandlerMapping 对象\n            OrderComparator.sort(this.handlerMappings);\n        }\n    } else {\n        try {\n            HandlerMapping hm = context.getBean(HANDLER_MAPPING_BEAN_NAME, HandlerMapping.class);\n            this.handlerMappings = Collections.singletonList(hm);\n        } catch (NoSuchBeanDefinitionException ex) {\n            // Ignore, we'll add a default HandlerMapping later.\n        }\n    }\n    // 如果没有 HandlerMapping，则加载默认的\n    if (this.handlerMappings == null) {\n        this.handlerMappings = getDefaultStrategies(context, HandlerMapping.class);\n    }\n}\n```\n\nInitHandlerAdapters方法同理\n\n2、处理请求：\n\nHttpServlet 提供了 doGet()、doPost() 等方法，DispatcherServlet 中这些方法是在其父类 FrameworkServlet 中实现的，这些方法有调用了processRequest()方法，再调用doService()方法。DispatcherServlet 的 doService() 方法主要是设置一些 request 属性，并调用 doDispatch() 方法进行请求分发处理，doDispatch() 方法的主要过程是通过 HandlerMapping 获取 Handler，再找到用于执行它的 HandlerAdapter，执行 Handler 后得到 ModelAndView ，ModelAndView 是连接“业务逻辑层”与“视图展示层”的桥梁，接下来就要通过 ModelAndView 获得 View，再通过它的 Model 对 View 进行渲染。\n\n# springmvc 处理流程\n\n1、  首先用户 发送请求—— >DispatcherServlet ， 分发器收到请求后自己不进行处理，而是委托给其他的解析器进行处理，作为统一访问点，进行全局的流程控制；\n\n2、  DispatcherServlet —— >HandlerMapping ， HandlerMapping 将会把请求映射为 HandlerExecutionChain 对象（包含一个 Handler 处理器（Controller）对象、多个 HandlerInterceptor 拦截器）对象，通过这种策略模式，很容易添加新的映射策略；\n\n3、  DispatcherServlet —— >HandlerAdapter ， HandlerAdapter 将会把处理器包装为适配器，从而支持多种类型的处理器，即适配器设计模式的应用，从而很容易支持很多类型的处理器；\n\n4、  HandlerAdapter —— > 处理器功能处理方法的调用， HandlerAdapter 将会根据适配的结果调用真正的处理器的功能处理方法，完成功能处理（在调用处理器前会先执行spring的前置拦截器preHandle）；并返回一个 ModelAndView 对象（包含模型数据、逻辑视图名），返回视图后会执行spring的后置拦截器postHandle；\n\n5、  ModelAndView 的逻辑视图名—— > ViewResolver ， ViewResolver 将把逻辑视图名解析为具体的 View，通过这种策略模式，很容易更换其他视图技术；\n\n6、  View —— > 渲染 ，View 会根据传进来的 Model 模型数据进行渲染，此处的 Model 实际是一个 Map 数据结构，因此很容易支持其他视图技术（这步处理完后执行spring的完成后拦截器）；\n\n7、  返回控制权给 DispatcherServlet ， 由 DispatcherServlet 返回响应给用户，到此一个流程结束。\n\n# IOC\n\n如果一个类A的功能实现需要借助于B，那么就成类B是类A的依赖，如果在类A的内部去实例化类B，那么两者之间会出现高耦合。一旦类B出现了问题，类A也需要进行改造，如果这样的情况较多，每个类之间有很多的依赖，那么就会出现牵一发而动全身的情况，程序会极难维护，并且很容易出现问题。要解决这个问题，就要把A类对B类的控制权抽离出来，交给第三方去做，把控制权反转给第三方，就称作控制反转（IOC）。控制反转是一种思想，是能够解决问题的一种可能的结果。而依赖注入是实现方式。由第三方通过构造函数、属性注入等方法，注入到A类，这样就极大程度的对类A和类B进行了解耦。\n\n- `BeanFactory`。基础类型`IoC容器`，提供完整的`IoC`服务支持。如果没有特殊指定，默认采用延迟初始化策略（`lazy-load`）。只有当客户端对象需要访问容器中的某个受管对象的时候，才对该受管对象进行初始化以及依赖注入操作。所以，相对来说，容器启动初期速度较快，所需要的资源有限。对于资源有限，并且功能要求不是很严格的场景，`BeanFactory`是比较合适的`IoC容器`选择。\n- `ApplicationContext`。`ApplicationContext`在`BeanFactory`的基础上构建，是相对比较高级的容器实现，除了拥有`BeanFactory`的所有支持，`ApplicationContext`还提供了其他高级特性，比如事件发布、国际化信息支持等，`ApplicationContext`所管理的对象，在该类型容器启动之后，默认全部初始化并绑定完成。所以，相对于`BeanFactory`来说，`ApplicationContext`要求更多的系统资源，同时，因为在启动时就完成所有初始化，容\n  器启动时间较之`BeanFactory`也会长一些。在那些系统资源充足，并且要求更多功能的场景中，`ApplicationContext`类型的容器是比较合适的选择。\n\n但是我们无论使用哪个容器，我们都需要通过某种方法告诉容器关于对象依赖的信息。\n\n在`BeanFactory`容器中，每一个注入对象都对应一个`BeanDefinition`实例对象，该实例对象负责保存注入对象的所有必要信息，包括其对应的对象的class类型、是否是抽象类、构造方法参数以及其他属性等。当客户端向`BeanFactory`请求相应对象的时候，`BeanFactory`会通过这些信息为客户端返回一个完备可用的对象实例。\n\n那么`BeanDefinition`实例对象的信息是从哪而来呢？这里就要引出一个专门加载解析配置文件的类了，他就是`BeanDefinitionReader`，对应到`xml`配置文件，就是他的子类`XmlBeanDefinitionReader`，`XmlBeanDefinitionReader`负责读取`Spring`指定格式的`XML`配置文件并解析，之后将解析后的文件内容映射到相应的`BeanDefinition`。\n\n我们把容器创造一个对象的过程称为`Bean的注册`，实现`Bean的注册`的接口为`BeanDefinitionRegistry`，其实`BeanFactory`只是一个接口，他定义了如何获取容器内对象的方法，我们所说的`BeanFactory`容器，其实是这个接口的是实现类，但是具体的`BeanFactory`实现类同时也会实现`BeanDefinitionRegistry`接口，这样我们才能通过容器注册对象和获取对象。我们通过`BeanDefinitionRegistry`的`rsgisterBeanDefinition(BeanDefinition beandefinition)`方法来进行`Bean的注册`。\n\n我们来总结一下一个Bean是如何注册到容器中，然后被我们获取的： 首先我们需要配置该Bean的依赖信息，通常我们配置在xml文件中，然后我们通过XmlBeanDefinitionReader读取文件内容，然后将文件内容映射到相应的BeanDefinition，然后我们可以通过BeanFactory和BeanDefinitionRegistry的具体实现类,比如DefaultListableBeanFactory实现Bean的注册和获取\n\nSpring`提供了一种叫做`BeanFactoryPostProcessor`的容器扩展机制。该机制允许我们在容器实例化相应对象之前，对注册到容器的`BeanDefinition`所保存的信息做相应的修改。\n\n首先是`BeanFactory`，我们也知道`BeanFactory`是`ApplicationContext`的父类，那么功能上`BeanFactory`也是比较弱小的，我们需要使用手动写代码来应用`BeanFactoryPostProcessor`\n\n接着是更高级的`ApplicationContext`容器，这个就牛逼多了，他可以自动识别容器中的`BeanFactoryPostProcessor`实例对象，并使用他们，是的，是“他们”，我们可以在一个容器中使用多个`BeanFactoryPostProcessor`\n\n# AOP\n\n- Aspect（切面）： Aspect 声明类似于 Java 中的类声明，在 Aspect 中会包含着一些 Pointcut 以及相应的 Advice。\n  Joint point（连接点）：表示在程序中明确定义的点，典型的包括方法调用，对类成员的访问以及异常处理程序块的执行等等，它自身还可以嵌套其它 joint point。\n- Pointcut（切点）：表示一组 joint point，这些 joint point 或是通过逻辑关系组合起来，或是通过通配、正则表达式等方式集中起来，它定义了相应的 Advice 将要发生的地方。\n- Advice（增强）：Advice 定义了在 Pointcut 里面定义的程序点具体要做的操作，它通过 before、after 和 around 来区别是在每个 joint point 之前、之后还是代替执行的代码。\n- Target（目标对象）：织入 Advice 的目标对象.。\n- Weaving（织入）：将 Aspect 和其他对象连接起来, 并创建 Adviced object 的过程\n\nAOP中的Joinpoint可以有多种类型：构造方法调用，字段的设置和获取，方法的调用，方法的执行，异常的处理执行，类的初始化。也就是说在AOP的概念中我们可以在上面的这些Joinpoint上织入我们自定义的Advice，但是在Spring中却没有实现上面所有的joinpoint，确切的说，Spring只支持方法执行类型的Joinpoint。\n\nAdvice 的类型\n\nbefore advice, 在 join point 前被执行的 advice. 虽然 before advice 是在 join point 前被执行, 但是它并不能够阻止 join point 的执行, 除非发生了异常(即我们在 before advice 代码中, 不能人为地决定是否继续执行 join point 中的代码)\n\n- after return advice, 在一个 join point 正常返回后执行的 advice\n- after throwing advice, 当一个 join point 抛出异常后执行的 advice\n- after(final) advice, 无论一个 join point 是正常退出还是发生了异常, 都会被执行的 advice.\n- around advice, 在 join point 前和 joint point 退出后都执行的 advice. 这个是最常用的 advice.\n- introduction，introduction可以为原有的对象增加新的属性和方法。\n\n在Spring中，通过动态代理和动态字节码技术实现了AOP，这些内容，我们将在以后进行讲解。\n\n**AOP 名词的大白话解说**\n\n　　1、**通知**　　--  Advice\n\n　　　　**就是要给目标类织入的事情**。就是我们说的额外的一些共同的事情，也就是上面说的 事务，日志等。你给先定义好，然后在想用的地方用一下。\n\n　　2、**连接点**　　-- JoinPoint\n\n 　　　　就是 spring 允许你使用通知的地方，那可真就多了，基本每个方法的前，后（两者都有也行），或抛出异常时都可以是连接点，spring 的话只支持方法连接点。和方法有关的前前后后（抛出异常），都是连接点。**一个类的所有方法前、后、抛出异常时等都是连接点。**\n\n　　3、**切入点**　　-- Pointcut\n\n　　　　上面说的连接点的基础上，来定义切入点，你的一个类里，有15个方法，那就有几十个连接点了对把，但是你并不想在所有方法附近都使用通知（使用叫织入，下面再说），你只想让其中的几个，在调用这几个方法之前，之后或者抛出异常时干点什么，那么就用切点来定义这几个方法，让切点来筛选连接点，选中那几个你想要的方法。（比如需要开启事务的只是“ save * ”、“ update * ”..等等这些方法）。**切入点就是定义了哪个类里面的哪些方法的会得到通知**。\n\n　　4、**切面**　　-- Aspect\n\n　　　　**切面是通知和切入点的结合**。现在发现了吧，没连接点什么事情，连接点就是为了让你好理解切点，搞出来的，明白这个概念就行了。**通知说明了干什么**和什么时候干（什么时候通过方法名中的before,after，around等就能知道），而**切入点说明了在哪干**（指定到底是哪个方法），这就是一个完整的切面定义。\n\n　　5、**织入**　　-- weaving\n\n　　　　**把切面应用到目标对象来创建新的代理对象的过程。**可以在编译时、类加载时、运行时完成的织入，spring 采用的是 **在运行时完成织入**。\n\n　　6、**引入**　　-- introduction\n\n　　　　允许我们向现有的类添加新方法属性。这不就是把切面（也就是新方法属性：通知定义的）用到目标类中吗~\n\n　　7、**目标**　　-- target\n\n　　　　引入中所提到的目标类，也就是**要被通知的对象**，**也就是真正的业务逻辑**，他可以在毫不知情的情况下，被咱们织入切面。而自己专注于业务本身的逻辑。\n\n　　8、**AOP 的代理**　　-- AOP Proxy\n\n　　　　**目标对象被织入增强后产生的结果类。**我的理解它是 spring 为了骗过 jvm 的类型检查，搞出来的一个伪装类。\n\n　　　　spring 伪装采用了两种方式：\n\n　　　　① 实现和目标类相同的接口　　-- 与目标类为双胞胎兄弟（要找我哥办事，弟弟我冒充哥哥收点礼物，再让我哥给你办事~）\n\n　　　　② 生成子类调用　　-- 给目标类当儿子（学会了爸爸的本事，都找我办就好了，但是我要先收点礼物~）\n\n在Spring的AOP编程中:如果加入容器的目标对象有实现接口,用JDK代理;如果目标对象没有实现接口,用Cglib代理\n\n# Java的代理模式\n\n### 静态代理\n\n静态代理在使用时,需要定义接口或者父类,被代理对象与代理对象一起实现相同的接口或者是继承相同父类.\n\n### 动态代理\n\n- 代理对象,不需要实现接口\n- 代理对象的生成,是利用JDK的API,动态的在内存中构建代理对象(需要我们指定创建代理对象/目标对象实现的接口的类型)\n\n```java\nstatic Object newProxyInstance(ClassLoader loader, Class<?>[] interfaces,InvocationHandler h )\n```\n\n参数含义：\n\n- `ClassLoader loader,`:指定当前目标对象使用类加载器,获取加载器的方法是固定的\n- `Class<?>[] interfaces,`:目标对象实现的接口的类型,使用泛型方式确认类型\n- `InvocationHandler h`:事件处理,执行目标对象的方法时,会触发事件处理器的方法,会把当前执行目标对象的方法作为参数传入\n\n### Cglib代理\n\n上面的静态代理和动态代理模式都是要求目标对象是实现一个接口的目标对象,但是有时候目标对象只是一个单独的对象,并没有实现任何的接口,这个时候就可以使用以目标对象子类的方式类实现代理,这种方法就叫做:Cglib代理\n\nCglib代理,也叫作子类代理,它是在内存中构建一个子类对象从而实现对目标对象功能的扩展.\n\n- JDK的动态代理有一个限制,就是使用动态代理的对象必须实现一个或多个接口,如果想代理没有实现接口的类,就可以使用Cglib实现.\n- Cglib是一个强大的高性能的代码生成包,它可以在运行期扩展java类与实现java接口.它广泛的被许多AOP的框架使用,例如Spring AOP和synaop,为他们提供方法的interception(拦截)\n- Cglib包的底层是通过使用一个小而块的字节码处理框架ASM来转换字节码并生成新的类.不鼓励直接使用ASM,因为它要求你必须对JVM内部结构包括class文件的格式和指令集都很熟悉.\n\nCglib子类代理实现方法:\n\n- 需要引入cglib的jar文件,但是Spring的核心包中已经包括了Cglib功能,所以直接引入`pring-core-3.2.5.jar`即可.\n- 引入功能包后,就可以在内存中动态构建子类\n- 代理的类不能为final,否则报错\n- 目标对象的方法如果为final/static,那么就不会被拦截,即不会执行目标对象额外的业务方法.\n\n# Spring 循环引用\n\n当Spring容器在创建A时，会发现其引用了B，从而会先去创建B。同样的，创建B时，会先去创建C，而创建C时，又先去创建A。最后A、B、C之间互相等待，谁都没法创建成功。\n\n要想打破这个环，那么这个环中至少需要有一个bean可以在自身的依赖还没有得到满足前，就能够被创建出来（最起码要被实例化出来，可以先不注入其需要的依赖）。这种bean只能是通过属性注入依赖的类，因为它们可以先使用默认构造器创建出实例，然后再通过setter方法注入依赖。而通过构造器注入依赖的类，在它的依赖没有被满足前，无法被实例化。而且这个bean，还必须是singleton，不能是prototype。\n\nSpring容器启动后，如果我们去获取singletonA，那么容器的操作步骤大致如下：\n\n- 尝试创建bean singletonA，发现singletonA是singleton，且不是通过构造器注入依赖，那么先使用默认构造器创建一个A的实例，并保存对它的引用，并且将singletonA标记为“正在创建中的singleton”。然后发现singletonA依赖了singletonB，所以尝试创建singletonB。\n- 尝试创建bean singletonB，发现singletonB是singleton，且不是通过构造器注入依赖，那么先使用默认构造器创建一个B的实例，并保存对它的引用，并且将singletonB标记为“正在创建中的singleton”。然后发现singletonB依赖了singletonA，所以尝试创建singletonA。\n- 尝试创建singletonA，注意，这时Spring容器发现singletonA“正在创建中”，那么就不会再去创建singletonA，而是返回容器之前保存了的对singletonA的引用。\n- 容器将singletonA通过setter方法注入到singletonB，从而singletonB完成创建。\n- 容器将singletonB通过setter方法注入到singletonA，从而singletonA完成创建。\n\n上述步骤，最重要的是第1步和第3步。在第1步中，容器会保存对singletonA的引用，在第3步中，再返回对singletonA的引用，从而可以成功创建那些依赖了singletonA的bean（本例中是singletonB）。这样，循环依赖的环就在singletonA这个点这里被打破。\n\n**那为什么prototype不能成为打破这个环的一个点呢？原因就在于Spring容器只会对singleton保存引用，而对于prototype，并不会对其保存引用，这就导致在第3步中并不能获得之前创建的bean（因为引用不到它）。**\n\n至于为什么容器不对prototype保存引用，那就涉及到singleton和portotpye的概念，如果也对prototype保存引用，那么其实它就变成了singleton。可以看一下Spring作用域。\n\n按道理，在循环依赖的环里，只要有一个bean，是通过属性注入依赖，并且是singleton，那么这个环就可以被打破，无论获取他们的顺序是怎样。但是我们在第五节得出过结论“只有当获取的第一个bean是通过属性注入依赖的singleton时，才会成功”，为什么会这样呢？这就和Spring的实现有关了，当Spring容器遍历那些循环依赖的bean时，只要遍历到那种已经遍历过一次的bean，并且它们不是通过属性注入依赖的singleton时，就会直接抛出BeanCurrentlyInCreationException异常。\n\n","tags":["Spring"]}]